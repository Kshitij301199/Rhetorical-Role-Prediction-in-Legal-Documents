{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitij/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kshitij/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(),'..')))\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from models.CNN_BiLSTM import CNN_BiLSTM\n",
    "from utils import sent2wordemb, label_encode\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoded(directory, filename):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        target_encoded = pickle.load(f)\n",
    "    \n",
    "    return target_encoded\n",
    "def save_encoded(target_encoded, directory, filename):\n",
    "    if not os.path.exists(os.path.join(directory)):\n",
    "        os.makedirs(os.path.join(directory))\n",
    "         \n",
    "    filepath = os.path.join(directory, filename)\n",
    "    # print(filepath)\n",
    "\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(target_encoded, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents : 247\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents : {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document number : 0\n",
      "Number of sentences : 91\n",
      "Document number : 1\n",
      "Number of sentences : 72\n",
      "Document number : 2\n",
      "Number of sentences : 200\n",
      "Document number : 3\n",
      "Number of sentences : 119\n",
      "Document number : 4\n",
      "Number of sentences : 184\n",
      "Document number : 5\n",
      "Number of sentences : 211\n",
      "Document number : 6\n",
      "Number of sentences : 140\n",
      "Document number : 7\n",
      "Number of sentences : 87\n",
      "Document number : 8\n",
      "Number of sentences : 228\n",
      "Document number : 9\n",
      "Number of sentences : 99\n",
      "Document number : 10\n",
      "Number of sentences : 62\n",
      "Document number : 11\n",
      "Number of sentences : 213\n",
      "Document number : 12\n",
      "Number of sentences : 111\n",
      "Document number : 13\n",
      "Number of sentences : 199\n",
      "Document number : 14\n",
      "Number of sentences : 188\n",
      "Document number : 15\n",
      "Number of sentences : 271\n",
      "Document number : 16\n",
      "Number of sentences : 43\n",
      "Document number : 17\n",
      "Number of sentences : 82\n",
      "Document number : 18\n",
      "Number of sentences : 171\n",
      "Document number : 19\n",
      "Number of sentences : 149\n",
      "Document number : 20\n",
      "Number of sentences : 95\n",
      "Document number : 21\n",
      "Number of sentences : 56\n",
      "Document number : 22\n",
      "Number of sentences : 47\n",
      "Document number : 23\n",
      "Number of sentences : 116\n",
      "Document number : 24\n",
      "Number of sentences : 111\n",
      "Document number : 25\n",
      "Number of sentences : 45\n",
      "Document number : 26\n",
      "Number of sentences : 109\n",
      "Document number : 27\n",
      "Number of sentences : 155\n",
      "Document number : 28\n",
      "Number of sentences : 198\n",
      "Document number : 29\n",
      "Number of sentences : 153\n",
      "Document number : 30\n",
      "Number of sentences : 50\n",
      "Document number : 31\n",
      "Number of sentences : 44\n",
      "Document number : 32\n",
      "Number of sentences : 264\n",
      "Document number : 33\n",
      "Number of sentences : 114\n",
      "Document number : 34\n",
      "Number of sentences : 54\n",
      "Document number : 35\n",
      "Number of sentences : 243\n",
      "Document number : 36\n",
      "Number of sentences : 107\n",
      "Document number : 37\n",
      "Number of sentences : 127\n",
      "Document number : 38\n",
      "Number of sentences : 188\n",
      "Document number : 39\n",
      "Number of sentences : 189\n",
      "Document number : 40\n",
      "Number of sentences : 157\n",
      "Document number : 41\n",
      "Number of sentences : 62\n",
      "Document number : 42\n",
      "Number of sentences : 120\n",
      "Document number : 43\n",
      "Number of sentences : 142\n",
      "Document number : 44\n",
      "Number of sentences : 75\n",
      "Document number : 45\n",
      "Number of sentences : 146\n",
      "Document number : 46\n",
      "Number of sentences : 185\n",
      "Document number : 47\n",
      "Number of sentences : 53\n",
      "Document number : 48\n",
      "Number of sentences : 73\n",
      "Document number : 49\n",
      "Number of sentences : 79\n",
      "Document number : 50\n",
      "Number of sentences : 187\n",
      "Document number : 51\n",
      "Number of sentences : 82\n",
      "Document number : 52\n",
      "Number of sentences : 88\n",
      "Document number : 53\n",
      "Number of sentences : 59\n",
      "Document number : 54\n",
      "Number of sentences : 59\n",
      "Document number : 55\n",
      "Number of sentences : 110\n",
      "Document number : 56\n",
      "Number of sentences : 141\n",
      "Document number : 57\n",
      "Number of sentences : 31\n",
      "Document number : 58\n",
      "Number of sentences : 54\n",
      "Document number : 59\n",
      "Number of sentences : 54\n",
      "Document number : 60\n",
      "Number of sentences : 31\n",
      "Document number : 61\n",
      "Number of sentences : 39\n",
      "Document number : 62\n",
      "Number of sentences : 208\n",
      "Document number : 63\n",
      "Number of sentences : 115\n",
      "Document number : 64\n",
      "Number of sentences : 155\n",
      "Document number : 65\n",
      "Number of sentences : 123\n",
      "Document number : 66\n",
      "Number of sentences : 52\n",
      "Document number : 67\n",
      "Number of sentences : 143\n",
      "Document number : 68\n",
      "Number of sentences : 142\n",
      "Document number : 69\n",
      "Number of sentences : 0\n",
      "Document number : 70\n",
      "Number of sentences : 77\n",
      "Document number : 71\n",
      "Number of sentences : 116\n",
      "Document number : 72\n",
      "Number of sentences : 87\n",
      "Document number : 73\n",
      "Number of sentences : 122\n",
      "Document number : 74\n",
      "Number of sentences : 111\n",
      "Document number : 75\n",
      "Number of sentences : 95\n",
      "Document number : 76\n",
      "Number of sentences : 184\n",
      "Document number : 77\n",
      "Number of sentences : 144\n",
      "Document number : 78\n",
      "Number of sentences : 35\n",
      "Document number : 79\n",
      "Number of sentences : 140\n",
      "Document number : 80\n",
      "Number of sentences : 73\n",
      "Document number : 81\n",
      "Number of sentences : 137\n",
      "Document number : 82\n",
      "Number of sentences : 24\n",
      "Document number : 83\n",
      "Number of sentences : 113\n",
      "Document number : 84\n",
      "Number of sentences : 105\n",
      "Document number : 85\n",
      "Number of sentences : 80\n",
      "Document number : 86\n",
      "Number of sentences : 106\n",
      "Document number : 87\n",
      "Number of sentences : 44\n",
      "Document number : 88\n",
      "Number of sentences : 105\n",
      "Document number : 89\n",
      "Number of sentences : 53\n",
      "Document number : 90\n",
      "Number of sentences : 136\n",
      "Document number : 91\n",
      "Number of sentences : 83\n",
      "Document number : 92\n",
      "Number of sentences : 221\n",
      "Document number : 93\n",
      "Number of sentences : 150\n",
      "Document number : 94\n",
      "Number of sentences : 114\n",
      "Document number : 95\n",
      "Number of sentences : 57\n",
      "Document number : 96\n",
      "Number of sentences : 57\n",
      "Document number : 97\n",
      "Number of sentences : 70\n",
      "Document number : 98\n",
      "Number of sentences : 264\n",
      "Document number : 99\n",
      "Number of sentences : 167\n",
      "Document number : 100\n",
      "Number of sentences : 49\n",
      "Document number : 101\n",
      "Number of sentences : 63\n",
      "Document number : 102\n",
      "Number of sentences : 74\n",
      "Document number : 103\n",
      "Number of sentences : 123\n",
      "Document number : 104\n",
      "Number of sentences : 147\n",
      "Document number : 105\n",
      "Number of sentences : 180\n",
      "Document number : 106\n",
      "Number of sentences : 71\n",
      "Document number : 107\n",
      "Number of sentences : 174\n",
      "Document number : 108\n",
      "Number of sentences : 126\n",
      "Document number : 109\n",
      "Number of sentences : 129\n",
      "Document number : 110\n",
      "Number of sentences : 32\n",
      "Document number : 111\n",
      "Number of sentences : 121\n",
      "Document number : 112\n",
      "Number of sentences : 60\n",
      "Document number : 113\n",
      "Number of sentences : 94\n",
      "Document number : 114\n",
      "Number of sentences : 121\n",
      "Document number : 115\n",
      "Number of sentences : 115\n",
      "Document number : 116\n",
      "Number of sentences : 153\n",
      "Document number : 117\n",
      "Number of sentences : 308\n",
      "Document number : 118\n",
      "Number of sentences : 44\n",
      "Document number : 119\n",
      "Number of sentences : 139\n",
      "Document number : 120\n",
      "Number of sentences : 71\n",
      "Document number : 121\n",
      "Number of sentences : 63\n",
      "Document number : 122\n",
      "Number of sentences : 201\n",
      "Document number : 123\n",
      "Number of sentences : 31\n",
      "Document number : 124\n",
      "Number of sentences : 168\n",
      "Document number : 125\n",
      "Number of sentences : 213\n",
      "Document number : 126\n",
      "Number of sentences : 96\n",
      "Document number : 127\n",
      "Number of sentences : 85\n",
      "Document number : 128\n",
      "Number of sentences : 174\n",
      "Document number : 129\n",
      "Number of sentences : 53\n",
      "Document number : 130\n",
      "Number of sentences : 111\n",
      "Document number : 131\n",
      "Number of sentences : 130\n",
      "Document number : 132\n",
      "Number of sentences : 126\n",
      "Document number : 133\n",
      "Number of sentences : 158\n",
      "Document number : 134\n",
      "Number of sentences : 103\n",
      "Document number : 135\n",
      "Number of sentences : 130\n",
      "Document number : 136\n",
      "Number of sentences : 65\n",
      "Document number : 137\n",
      "Number of sentences : 98\n",
      "Document number : 138\n",
      "Number of sentences : 161\n",
      "Document number : 139\n",
      "Number of sentences : 93\n",
      "Document number : 140\n",
      "Number of sentences : 67\n",
      "Document number : 141\n",
      "Number of sentences : 173\n",
      "Document number : 142\n",
      "Number of sentences : 234\n",
      "Document number : 143\n",
      "Number of sentences : 153\n",
      "Document number : 144\n",
      "Number of sentences : 103\n",
      "Document number : 145\n",
      "Number of sentences : 42\n",
      "Document number : 146\n",
      "Number of sentences : 164\n",
      "Document number : 147\n",
      "Number of sentences : 36\n",
      "Document number : 148\n",
      "Number of sentences : 66\n",
      "Document number : 149\n",
      "Number of sentences : 386\n",
      "Document number : 150\n",
      "Number of sentences : 119\n",
      "Document number : 151\n",
      "Number of sentences : 83\n",
      "Document number : 152\n",
      "Number of sentences : 200\n",
      "Document number : 153\n",
      "Number of sentences : 159\n",
      "Document number : 154\n",
      "Number of sentences : 75\n",
      "Document number : 155\n",
      "Number of sentences : 75\n",
      "Document number : 156\n",
      "Number of sentences : 63\n",
      "Document number : 157\n",
      "Number of sentences : 65\n",
      "Document number : 158\n",
      "Number of sentences : 97\n",
      "Document number : 159\n",
      "Number of sentences : 75\n",
      "Document number : 160\n",
      "Number of sentences : 104\n",
      "Document number : 161\n",
      "Number of sentences : 44\n",
      "Document number : 162\n",
      "Number of sentences : 63\n",
      "Document number : 163\n",
      "Number of sentences : 79\n",
      "Document number : 164\n",
      "Number of sentences : 190\n",
      "Document number : 165\n",
      "Number of sentences : 33\n",
      "Document number : 166\n",
      "Number of sentences : 91\n",
      "Document number : 167\n",
      "Number of sentences : 96\n",
      "Document number : 168\n",
      "Number of sentences : 52\n",
      "Document number : 169\n",
      "Number of sentences : 91\n",
      "Document number : 170\n",
      "Number of sentences : 251\n",
      "Document number : 171\n",
      "Number of sentences : 117\n",
      "Document number : 172\n",
      "Number of sentences : 146\n",
      "Document number : 173\n",
      "Number of sentences : 84\n",
      "Document number : 174\n",
      "Number of sentences : 223\n",
      "Document number : 175\n",
      "Number of sentences : 54\n",
      "Document number : 176\n",
      "Number of sentences : 248\n",
      "Document number : 177\n",
      "Number of sentences : 69\n",
      "Document number : 178\n",
      "Number of sentences : 89\n",
      "Document number : 179\n",
      "Number of sentences : 124\n",
      "Document number : 180\n",
      "Number of sentences : 45\n",
      "Document number : 181\n",
      "Number of sentences : 95\n",
      "Document number : 182\n",
      "Number of sentences : 131\n",
      "Document number : 183\n",
      "Number of sentences : 117\n",
      "Document number : 184\n",
      "Number of sentences : 27\n",
      "Document number : 185\n",
      "Number of sentences : 106\n",
      "Document number : 186\n",
      "Number of sentences : 244\n",
      "Document number : 187\n",
      "Number of sentences : 87\n",
      "Document number : 188\n",
      "Number of sentences : 78\n",
      "Document number : 189\n",
      "Number of sentences : 97\n",
      "Document number : 190\n",
      "Number of sentences : 36\n",
      "Document number : 191\n",
      "Number of sentences : 128\n",
      "Document number : 192\n",
      "Number of sentences : 154\n",
      "Document number : 193\n",
      "Number of sentences : 115\n",
      "Document number : 194\n",
      "Number of sentences : 61\n",
      "Document number : 195\n",
      "Number of sentences : 245\n",
      "Document number : 196\n",
      "Number of sentences : 104\n",
      "Document number : 197\n",
      "Number of sentences : 91\n",
      "Document number : 198\n",
      "Number of sentences : 120\n",
      "Document number : 199\n",
      "Number of sentences : 89\n",
      "Document number : 200\n",
      "Number of sentences : 65\n",
      "Document number : 201\n",
      "Number of sentences : 74\n",
      "Document number : 202\n",
      "Number of sentences : 92\n",
      "Document number : 203\n",
      "Number of sentences : 240\n",
      "Document number : 204\n",
      "Number of sentences : 102\n",
      "Document number : 205\n",
      "Number of sentences : 107\n",
      "Document number : 206\n",
      "Number of sentences : 79\n",
      "Document number : 207\n",
      "Number of sentences : 168\n",
      "Document number : 208\n",
      "Number of sentences : 181\n",
      "Document number : 209\n",
      "Number of sentences : 53\n",
      "Document number : 210\n",
      "Number of sentences : 248\n",
      "Document number : 211\n",
      "Number of sentences : 141\n",
      "Document number : 212\n",
      "Number of sentences : 47\n",
      "Document number : 213\n",
      "Number of sentences : 81\n",
      "Document number : 214\n",
      "Number of sentences : 82\n",
      "Document number : 215\n",
      "Number of sentences : 60\n",
      "Document number : 216\n",
      "Number of sentences : 179\n",
      "Document number : 217\n",
      "Number of sentences : 65\n",
      "Document number : 218\n",
      "Number of sentences : 176\n",
      "Document number : 219\n",
      "Number of sentences : 283\n",
      "Document number : 220\n",
      "Number of sentences : 123\n",
      "Document number : 221\n",
      "Number of sentences : 263\n",
      "Document number : 222\n",
      "Number of sentences : 58\n",
      "Document number : 223\n",
      "Number of sentences : 193\n",
      "Document number : 224\n",
      "Number of sentences : 150\n",
      "Document number : 225\n",
      "Number of sentences : 0\n",
      "Document number : 226\n",
      "Number of sentences : 148\n",
      "Document number : 227\n",
      "Number of sentences : 45\n",
      "Document number : 228\n",
      "Number of sentences : 255\n",
      "Document number : 229\n",
      "Number of sentences : 66\n",
      "Document number : 230\n",
      "Number of sentences : 62\n",
      "Document number : 231\n",
      "Number of sentences : 214\n",
      "Document number : 232\n",
      "Number of sentences : 246\n",
      "Document number : 233\n",
      "Number of sentences : 110\n",
      "Document number : 234\n",
      "Number of sentences : 110\n",
      "Document number : 235\n",
      "Number of sentences : 67\n",
      "Document number : 236\n",
      "Number of sentences : 73\n",
      "Document number : 237\n",
      "Number of sentences : 56\n",
      "Document number : 238\n",
      "Number of sentences : 212\n",
      "Document number : 239\n",
      "Number of sentences : 215\n",
      "Document number : 240\n",
      "Number of sentences : 103\n",
      "Document number : 241\n",
      "Number of sentences : 45\n",
      "Document number : 242\n",
      "Number of sentences : 112\n",
      "Document number : 243\n",
      "Number of sentences : 77\n",
      "Document number : 244\n",
      "Number of sentences : 90\n",
      "Document number : 245\n",
      "Number of sentences : 122\n",
      "Document number : 246\n",
      "Number of sentences : 122\n",
      "Avg sentences = 117.35\n"
     ]
    }
   ],
   "source": [
    "total_sentences = 0\n",
    "group = []\n",
    "for index,doc in enumerate(data):\n",
    "    print(f\"Document number : {index}\")\n",
    "    print(f\"Number of sentences : {len(doc['annotations'][0]['result'])}\")\n",
    "    total_sentences += len(doc['annotations'][0]['result'])\n",
    "    group.append(doc['meta']['group'])\n",
    "    \n",
    "print(f\"Avg sentences = {total_sentences/len(data):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of law groups : \n",
      "{'Tax', 'Criminal'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of law groups : \\n{set(group)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through each document + sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document number : 0      Law Type : Criminal\n",
      "Avg number of chars : 180.81\n",
      "Document number : 1      Law Type : Tax\n",
      "Avg number of chars : 153.39\n",
      "Document number : 2      Law Type : Criminal\n",
      "Avg number of chars : 193.93\n",
      "Document number : 3      Law Type : Tax\n",
      "Avg number of chars : 222.87\n",
      "Document number : 4      Law Type : Tax\n",
      "Avg number of chars : 183.04\n",
      "Document number : 5      Law Type : Criminal\n",
      "Avg number of chars : 143.89\n",
      "Document number : 6      Law Type : Tax\n",
      "Avg number of chars : 202.29\n",
      "Document number : 7      Law Type : Criminal\n",
      "Avg number of chars : 118.03\n",
      "Document number : 8      Law Type : Criminal\n",
      "Avg number of chars : 140.69\n",
      "Document number : 9      Law Type : Criminal\n",
      "Avg number of chars : 181.81\n",
      "Document number : 10     Law Type : Criminal\n",
      "Avg number of chars : 153.18\n",
      "Document number : 11     Law Type : Tax\n",
      "Avg number of chars : 177.47\n",
      "Document number : 12     Law Type : Tax\n",
      "Avg number of chars : 156.68\n",
      "Document number : 13     Law Type : Criminal\n",
      "Avg number of chars : 125.26\n",
      "Document number : 14     Law Type : Criminal\n",
      "Avg number of chars : 157.27\n",
      "Document number : 15     Law Type : Criminal\n",
      "Avg number of chars : 156.87\n",
      "Document number : 16     Law Type : Criminal\n",
      "Avg number of chars : 158.00\n",
      "Document number : 17     Law Type : Tax\n",
      "Avg number of chars : 184.43\n",
      "Document number : 18     Law Type : Criminal\n",
      "Avg number of chars : 176.98\n",
      "Document number : 19     Law Type : Criminal\n",
      "Avg number of chars : 153.38\n",
      "Document number : 20     Law Type : Tax\n",
      "Avg number of chars : 191.87\n",
      "Document number : 21     Law Type : Criminal\n",
      "Avg number of chars : 206.07\n",
      "Document number : 22     Law Type : Criminal\n",
      "Avg number of chars : 121.66\n",
      "Document number : 23     Law Type : Criminal\n",
      "Avg number of chars : 148.36\n",
      "Document number : 24     Law Type : Tax\n",
      "Avg number of chars : 169.52\n",
      "Document number : 25     Law Type : Tax\n",
      "Avg number of chars : 209.18\n",
      "Document number : 26     Law Type : Tax\n",
      "Avg number of chars : 180.00\n",
      "Document number : 27     Law Type : Criminal\n",
      "Avg number of chars : 103.23\n",
      "Document number : 28     Law Type : Criminal\n",
      "Avg number of chars : 151.35\n",
      "Document number : 29     Law Type : Criminal\n",
      "Avg number of chars : 197.14\n",
      "Document number : 30     Law Type : Tax\n",
      "Avg number of chars : 158.82\n",
      "Document number : 31     Law Type : Tax\n",
      "Avg number of chars : 178.23\n",
      "Document number : 32     Law Type : Criminal\n",
      "Avg number of chars : 105.60\n",
      "Document number : 33     Law Type : Tax\n",
      "Avg number of chars : 190.95\n",
      "Document number : 34     Law Type : Criminal\n",
      "Avg number of chars : 142.96\n",
      "Document number : 35     Law Type : Criminal\n",
      "Avg number of chars : 158.38\n",
      "Document number : 36     Law Type : Criminal\n",
      "Avg number of chars : 170.88\n",
      "Document number : 37     Law Type : Criminal\n",
      "Avg number of chars : 155.44\n",
      "Document number : 38     Law Type : Criminal\n",
      "Avg number of chars : 194.41\n",
      "Document number : 39     Law Type : Criminal\n",
      "Avg number of chars : 167.41\n",
      "Document number : 40     Law Type : Tax\n",
      "Avg number of chars : 210.76\n",
      "Document number : 41     Law Type : Criminal\n",
      "Avg number of chars : 154.13\n",
      "Document number : 42     Law Type : Criminal\n",
      "Avg number of chars : 122.87\n",
      "Document number : 43     Law Type : Criminal\n",
      "Avg number of chars : 153.01\n",
      "Document number : 44     Law Type : Criminal\n",
      "Avg number of chars : 126.83\n",
      "Document number : 45     Law Type : Criminal\n",
      "Avg number of chars : 199.92\n",
      "Document number : 46     Law Type : Tax\n",
      "Avg number of chars : 186.91\n",
      "Document number : 47     Law Type : Tax\n",
      "Avg number of chars : 137.96\n",
      "Document number : 48     Law Type : Tax\n",
      "Avg number of chars : 107.45\n",
      "Document number : 49     Law Type : Criminal\n",
      "Avg number of chars : 118.38\n",
      "Document number : 50     Law Type : Criminal\n",
      "Avg number of chars : 147.52\n",
      "Document number : 51     Law Type : Tax\n",
      "Avg number of chars : 170.98\n",
      "Document number : 52     Law Type : Tax\n",
      "Avg number of chars : 184.92\n",
      "Document number : 53     Law Type : Tax\n",
      "Avg number of chars : 179.97\n",
      "Document number : 54     Law Type : Tax\n",
      "Avg number of chars : 199.10\n",
      "Document number : 55     Law Type : Criminal\n",
      "Avg number of chars : 177.52\n",
      "Document number : 56     Law Type : Criminal\n",
      "Avg number of chars : 189.53\n",
      "Document number : 57     Law Type : Tax\n",
      "Avg number of chars : 217.29\n",
      "Document number : 58     Law Type : Tax\n",
      "Avg number of chars : 156.94\n",
      "Document number : 59     Law Type : Criminal\n",
      "Avg number of chars : 146.57\n",
      "Document number : 60     Law Type : Tax\n",
      "Avg number of chars : 285.42\n",
      "Document number : 61     Law Type : Criminal\n",
      "Avg number of chars : 179.64\n",
      "Document number : 62     Law Type : Criminal\n",
      "Avg number of chars : 177.97\n",
      "Document number : 63     Law Type : Tax\n",
      "Avg number of chars : 206.77\n",
      "Document number : 64     Law Type : Criminal\n",
      "Avg number of chars : 143.66\n",
      "Document number : 65     Law Type : Tax\n",
      "Avg number of chars : 189.20\n",
      "Document number : 66     Law Type : Criminal\n",
      "Avg number of chars : 251.38\n",
      "Document number : 67     Law Type : Criminal\n",
      "Avg number of chars : 158.27\n",
      "Document number : 68     Law Type : Tax\n",
      "Avg number of chars : 238.18\n",
      "Document number : 69     Law Type : Criminal\n",
      "---------------------Document is empty----------------------\n",
      "Document number : 70     Law Type : Criminal\n",
      "Avg number of chars : 136.87\n",
      "Document number : 71     Law Type : Tax\n",
      "Avg number of chars : 185.29\n",
      "Document number : 72     Law Type : Tax\n",
      "Avg number of chars : 231.75\n",
      "Document number : 73     Law Type : Tax\n",
      "Avg number of chars : 223.84\n",
      "Document number : 74     Law Type : Tax\n",
      "Avg number of chars : 181.57\n",
      "Document number : 75     Law Type : Tax\n",
      "Avg number of chars : 215.92\n",
      "Document number : 76     Law Type : Tax\n",
      "Avg number of chars : 178.18\n",
      "Document number : 77     Law Type : Criminal\n",
      "Avg number of chars : 163.87\n",
      "Document number : 78     Law Type : Criminal\n",
      "Avg number of chars : 194.77\n",
      "Document number : 79     Law Type : Tax\n",
      "Avg number of chars : 242.19\n",
      "Document number : 80     Law Type : Tax\n",
      "Avg number of chars : 123.86\n",
      "Document number : 81     Law Type : Tax\n",
      "Avg number of chars : 188.51\n",
      "Document number : 82     Law Type : Criminal\n",
      "Avg number of chars : 239.83\n",
      "Document number : 83     Law Type : Criminal\n",
      "Avg number of chars : 205.27\n",
      "Document number : 84     Law Type : Criminal\n",
      "Avg number of chars : 173.30\n",
      "Document number : 85     Law Type : Tax\n",
      "Avg number of chars : 184.50\n",
      "Document number : 86     Law Type : Criminal\n",
      "Avg number of chars : 151.77\n",
      "Document number : 87     Law Type : Criminal\n",
      "Avg number of chars : 194.30\n",
      "Document number : 88     Law Type : Criminal\n",
      "Avg number of chars : 197.35\n",
      "Document number : 89     Law Type : Criminal\n",
      "Avg number of chars : 170.96\n",
      "Document number : 90     Law Type : Criminal\n",
      "Avg number of chars : 168.54\n",
      "Document number : 91     Law Type : Criminal\n",
      "Avg number of chars : 184.36\n",
      "Document number : 92     Law Type : Criminal\n",
      "Avg number of chars : 147.54\n",
      "Document number : 93     Law Type : Criminal\n",
      "Avg number of chars : 180.76\n",
      "Document number : 94     Law Type : Tax\n",
      "Avg number of chars : 198.94\n",
      "Document number : 95     Law Type : Tax\n",
      "Avg number of chars : 201.40\n",
      "Document number : 96     Law Type : Tax\n",
      "Avg number of chars : 120.51\n",
      "Document number : 97     Law Type : Criminal\n",
      "Avg number of chars : 125.64\n",
      "Document number : 98     Law Type : Tax\n",
      "Avg number of chars : 131.84\n",
      "Document number : 99     Law Type : Criminal\n",
      "Avg number of chars : 175.49\n",
      "Document number : 100    Law Type : Tax\n",
      "Avg number of chars : 167.49\n",
      "Document number : 101    Law Type : Tax\n",
      "Avg number of chars : 221.51\n",
      "Document number : 102    Law Type : Criminal\n",
      "Avg number of chars : 141.16\n",
      "Document number : 103    Law Type : Tax\n",
      "Avg number of chars : 239.26\n",
      "Document number : 104    Law Type : Criminal\n",
      "Avg number of chars : 149.54\n",
      "Document number : 105    Law Type : Criminal\n",
      "Avg number of chars : 159.09\n",
      "Document number : 106    Law Type : Criminal\n",
      "Avg number of chars : 165.13\n",
      "Document number : 107    Law Type : Criminal\n",
      "Avg number of chars : 121.44\n",
      "Document number : 108    Law Type : Criminal\n",
      "Avg number of chars : 197.20\n",
      "Document number : 109    Law Type : Tax\n",
      "Avg number of chars : 160.73\n",
      "Document number : 110    Law Type : Criminal\n",
      "Avg number of chars : 213.16\n",
      "Document number : 111    Law Type : Criminal\n",
      "Avg number of chars : 141.72\n",
      "Document number : 112    Law Type : Criminal\n",
      "Avg number of chars : 178.87\n",
      "Document number : 113    Law Type : Tax\n",
      "Avg number of chars : 202.00\n",
      "Document number : 114    Law Type : Tax\n",
      "Avg number of chars : 153.96\n",
      "Document number : 115    Law Type : Criminal\n",
      "Avg number of chars : 96.70\n",
      "Document number : 116    Law Type : Criminal\n",
      "Avg number of chars : 183.45\n",
      "Document number : 117    Law Type : Criminal\n",
      "Avg number of chars : 130.78\n",
      "Document number : 118    Law Type : Tax\n",
      "Avg number of chars : 147.84\n",
      "Document number : 119    Law Type : Criminal\n",
      "Avg number of chars : 130.66\n",
      "Document number : 120    Law Type : Criminal\n",
      "Avg number of chars : 134.48\n",
      "Document number : 121    Law Type : Criminal\n",
      "Avg number of chars : 120.60\n",
      "Document number : 122    Law Type : Tax\n",
      "Avg number of chars : 165.96\n",
      "Document number : 123    Law Type : Criminal\n",
      "Avg number of chars : 232.52\n",
      "Document number : 124    Law Type : Tax\n",
      "Avg number of chars : 156.58\n",
      "Document number : 125    Law Type : Tax\n",
      "Avg number of chars : 146.02\n",
      "Document number : 126    Law Type : Criminal\n",
      "Avg number of chars : 126.23\n",
      "Document number : 127    Law Type : Criminal\n",
      "Avg number of chars : 148.02\n",
      "Document number : 128    Law Type : Criminal\n",
      "Avg number of chars : 151.17\n",
      "Document number : 129    Law Type : Tax\n",
      "Avg number of chars : 146.09\n",
      "Document number : 130    Law Type : Criminal\n",
      "Avg number of chars : 120.59\n",
      "Document number : 131    Law Type : Tax\n",
      "Avg number of chars : 197.37\n",
      "Document number : 132    Law Type : Tax\n",
      "Avg number of chars : 181.74\n",
      "Document number : 133    Law Type : Criminal\n",
      "Avg number of chars : 133.90\n",
      "Document number : 134    Law Type : Criminal\n",
      "Avg number of chars : 150.83\n",
      "Document number : 135    Law Type : Tax\n",
      "Avg number of chars : 193.87\n",
      "Document number : 136    Law Type : Criminal\n",
      "Avg number of chars : 224.65\n",
      "Document number : 137    Law Type : Criminal\n",
      "Avg number of chars : 225.19\n",
      "Document number : 138    Law Type : Tax\n",
      "Avg number of chars : 174.61\n",
      "Document number : 139    Law Type : Tax\n",
      "Avg number of chars : 179.53\n",
      "Document number : 140    Law Type : Tax\n",
      "Avg number of chars : 150.78\n",
      "Document number : 141    Law Type : Criminal\n",
      "Avg number of chars : 161.98\n",
      "Document number : 142    Law Type : Criminal\n",
      "Avg number of chars : 149.09\n",
      "Document number : 143    Law Type : Criminal\n",
      "Avg number of chars : 203.50\n",
      "Document number : 144    Law Type : Tax\n",
      "Avg number of chars : 149.13\n",
      "Document number : 145    Law Type : Tax\n",
      "Avg number of chars : 188.52\n",
      "Document number : 146    Law Type : Criminal\n",
      "Avg number of chars : 120.12\n",
      "Document number : 147    Law Type : Criminal\n",
      "Avg number of chars : 181.19\n",
      "Document number : 148    Law Type : Tax\n",
      "Avg number of chars : 113.09\n",
      "Document number : 149    Law Type : Criminal\n",
      "Avg number of chars : 100.87\n",
      "Document number : 150    Law Type : Tax\n",
      "Avg number of chars : 211.39\n",
      "Document number : 151    Law Type : Tax\n",
      "Avg number of chars : 191.83\n",
      "Document number : 152    Law Type : Tax\n",
      "Avg number of chars : 184.89\n",
      "Document number : 153    Law Type : Tax\n",
      "Avg number of chars : 192.36\n",
      "Document number : 154    Law Type : Criminal\n",
      "Avg number of chars : 140.79\n",
      "Document number : 155    Law Type : Criminal\n",
      "Avg number of chars : 131.45\n",
      "Document number : 156    Law Type : Tax\n",
      "Avg number of chars : 126.51\n",
      "Document number : 157    Law Type : Criminal\n",
      "Avg number of chars : 153.66\n",
      "Document number : 158    Law Type : Tax\n",
      "Avg number of chars : 209.72\n",
      "Document number : 159    Law Type : Tax\n",
      "Avg number of chars : 170.19\n",
      "Document number : 160    Law Type : Criminal\n",
      "Avg number of chars : 132.71\n",
      "Document number : 161    Law Type : Tax\n",
      "Avg number of chars : 138.84\n",
      "Document number : 162    Law Type : Tax\n",
      "Avg number of chars : 163.06\n",
      "Document number : 163    Law Type : Criminal\n",
      "Avg number of chars : 185.28\n",
      "Document number : 164    Law Type : Criminal\n",
      "Avg number of chars : 163.82\n",
      "Document number : 165    Law Type : Tax\n",
      "Avg number of chars : 192.76\n",
      "Document number : 166    Law Type : Tax\n",
      "Avg number of chars : 199.42\n",
      "Document number : 167    Law Type : Tax\n",
      "Avg number of chars : 177.50\n",
      "Document number : 168    Law Type : Criminal\n",
      "Avg number of chars : 144.85\n",
      "Document number : 169    Law Type : Tax\n",
      "Avg number of chars : 204.69\n",
      "Document number : 170    Law Type : Criminal\n",
      "Avg number of chars : 122.97\n",
      "Document number : 171    Law Type : Criminal\n",
      "Avg number of chars : 146.98\n",
      "Document number : 172    Law Type : Criminal\n",
      "Avg number of chars : 189.48\n",
      "Document number : 173    Law Type : Criminal\n",
      "Avg number of chars : 165.60\n",
      "Document number : 174    Law Type : Tax\n",
      "Avg number of chars : 155.49\n",
      "Document number : 175    Law Type : Criminal\n",
      "Avg number of chars : 158.89\n",
      "Document number : 176    Law Type : Criminal\n",
      "Avg number of chars : 153.73\n",
      "Document number : 177    Law Type : Tax\n",
      "Avg number of chars : 200.87\n",
      "Document number : 178    Law Type : Criminal\n",
      "Avg number of chars : 213.38\n",
      "Document number : 179    Law Type : Criminal\n",
      "Avg number of chars : 153.81\n",
      "Document number : 180    Law Type : Criminal\n",
      "Avg number of chars : 183.78\n",
      "Document number : 181    Law Type : Tax\n",
      "Avg number of chars : 210.33\n",
      "Document number : 182    Law Type : Criminal\n",
      "Avg number of chars : 137.18\n",
      "Document number : 183    Law Type : Tax\n",
      "Avg number of chars : 140.44\n",
      "Document number : 184    Law Type : Criminal\n",
      "Avg number of chars : 257.48\n",
      "Document number : 185    Law Type : Criminal\n",
      "Avg number of chars : 223.09\n",
      "Document number : 186    Law Type : Tax\n",
      "Avg number of chars : 142.70\n",
      "Document number : 187    Law Type : Tax\n",
      "Avg number of chars : 96.03\n",
      "Document number : 188    Law Type : Tax\n",
      "Avg number of chars : 145.19\n",
      "Document number : 189    Law Type : Tax\n",
      "Avg number of chars : 238.24\n",
      "Document number : 190    Law Type : Tax\n",
      "Avg number of chars : 156.33\n",
      "Document number : 191    Law Type : Criminal\n",
      "Avg number of chars : 139.73\n",
      "Document number : 192    Law Type : Criminal\n",
      "Avg number of chars : 116.26\n",
      "Document number : 193    Law Type : Criminal\n",
      "Avg number of chars : 143.90\n",
      "Document number : 194    Law Type : Tax\n",
      "Avg number of chars : 177.48\n",
      "Document number : 195    Law Type : Criminal\n",
      "Avg number of chars : 141.11\n",
      "Document number : 196    Law Type : Criminal\n",
      "Avg number of chars : 209.69\n",
      "Document number : 197    Law Type : Tax\n",
      "Avg number of chars : 173.37\n",
      "Document number : 198    Law Type : Criminal\n",
      "Avg number of chars : 139.67\n",
      "Document number : 199    Law Type : Tax\n",
      "Avg number of chars : 121.91\n",
      "Document number : 200    Law Type : Tax\n",
      "Avg number of chars : 192.60\n",
      "Document number : 201    Law Type : Criminal\n",
      "Avg number of chars : 191.55\n",
      "Document number : 202    Law Type : Criminal\n",
      "Avg number of chars : 182.96\n",
      "Document number : 203    Law Type : Criminal\n",
      "Avg number of chars : 130.49\n",
      "Document number : 204    Law Type : Criminal\n",
      "Avg number of chars : 241.65\n",
      "Document number : 205    Law Type : Tax\n",
      "Avg number of chars : 199.80\n",
      "Document number : 206    Law Type : Tax\n",
      "Avg number of chars : 109.53\n",
      "Document number : 207    Law Type : Tax\n",
      "Avg number of chars : 156.56\n",
      "Document number : 208    Law Type : Tax\n",
      "Avg number of chars : 184.97\n",
      "Document number : 209    Law Type : Tax\n",
      "Avg number of chars : 147.19\n",
      "Document number : 210    Law Type : Criminal\n",
      "Avg number of chars : 138.00\n",
      "Document number : 211    Law Type : Tax\n",
      "Avg number of chars : 180.89\n",
      "Document number : 212    Law Type : Criminal\n",
      "Avg number of chars : 199.21\n",
      "Document number : 213    Law Type : Tax\n",
      "Avg number of chars : 182.35\n",
      "Document number : 214    Law Type : Tax\n",
      "Avg number of chars : 235.80\n",
      "Document number : 215    Law Type : Tax\n",
      "Avg number of chars : 127.67\n",
      "Document number : 216    Law Type : Tax\n",
      "Avg number of chars : 140.34\n",
      "Document number : 217    Law Type : Criminal\n",
      "Avg number of chars : 242.34\n",
      "Document number : 218    Law Type : Criminal\n",
      "Avg number of chars : 176.73\n",
      "Document number : 219    Law Type : Criminal\n",
      "Avg number of chars : 145.11\n",
      "Document number : 220    Law Type : Criminal\n",
      "Avg number of chars : 149.50\n",
      "Document number : 221    Law Type : Criminal\n",
      "Avg number of chars : 96.02\n",
      "Document number : 222    Law Type : Tax\n",
      "Avg number of chars : 252.79\n",
      "Document number : 223    Law Type : Tax\n",
      "Avg number of chars : 163.40\n",
      "Document number : 224    Law Type : Criminal\n",
      "Avg number of chars : 180.76\n",
      "Document number : 225    Law Type : Tax\n",
      "---------------------Document is empty----------------------\n",
      "Document number : 226    Law Type : Criminal\n",
      "Avg number of chars : 125.99\n",
      "Document number : 227    Law Type : Tax\n",
      "Avg number of chars : 138.91\n",
      "Document number : 228    Law Type : Criminal\n",
      "Avg number of chars : 142.22\n",
      "Document number : 229    Law Type : Criminal\n",
      "Avg number of chars : 125.71\n",
      "Document number : 230    Law Type : Criminal\n",
      "Avg number of chars : 191.84\n",
      "Document number : 231    Law Type : Criminal\n",
      "Avg number of chars : 105.37\n",
      "Document number : 232    Law Type : Tax\n",
      "Avg number of chars : 141.54\n",
      "Document number : 233    Law Type : Tax\n",
      "Avg number of chars : 188.23\n",
      "Document number : 234    Law Type : Criminal\n",
      "Avg number of chars : 133.46\n",
      "Document number : 235    Law Type : Tax\n",
      "Avg number of chars : 100.45\n",
      "Document number : 236    Law Type : Criminal\n",
      "Avg number of chars : 115.60\n",
      "Document number : 237    Law Type : Criminal\n",
      "Avg number of chars : 262.32\n",
      "Document number : 238    Law Type : Criminal\n",
      "Avg number of chars : 187.57\n",
      "Document number : 239    Law Type : Criminal\n",
      "Avg number of chars : 157.16\n",
      "Document number : 240    Law Type : Criminal\n",
      "Avg number of chars : 158.80\n",
      "Document number : 241    Law Type : Tax\n",
      "Avg number of chars : 134.04\n",
      "Document number : 242    Law Type : Criminal\n",
      "Avg number of chars : 139.70\n",
      "Document number : 243    Law Type : Tax\n",
      "Avg number of chars : 128.68\n",
      "Document number : 244    Law Type : Tax\n",
      "Avg number of chars : 257.60\n",
      "Document number : 245    Law Type : Criminal\n",
      "Avg number of chars : 128.81\n",
      "Document number : 246    Law Type : Criminal\n",
      "Avg number of chars : 177.61\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for index,doc in enumerate(data):\n",
    "    char_count = 0\n",
    "    group = doc['meta']['group']\n",
    "    print(f\"Document number : {index:<6} Law Type : {group}\")\n",
    "    # print(f\"Number of sentences : {len(doc['annotations'][0]['result'])}\")\n",
    "    if doc['annotations'][0]['result'] != []:\n",
    "        for sentence_data in doc['annotations'][0]['result']:\n",
    "            char_count += len(sentence_data['value']['text'])\n",
    "            labels.append(sentence_data['value']['labels'][0])\n",
    "        print(f\"Avg number of chars : {char_count/len(doc['annotations'][0]['result']):.2f}\")\n",
    "    else:\n",
    "        print(f\"{'Document is empty':-^60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ISSUE', 'FAC', 'NONE', 'ARG_PETITIONER', 'PRE_NOT_RELIED', 'STA', 'RPC', 'ARG_RESPONDENT', 'PREAMBLE', 'ANALYSIS', 'RLC', 'PRE_RELIED', 'RATIO'}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PREAMBLE': 4167,\n",
       "         'NONE': 1423,\n",
       "         'FAC': 5744,\n",
       "         'ARG_RESPONDENT': 698,\n",
       "         'RLC': 752,\n",
       "         'ARG_PETITIONER': 1315,\n",
       "         'ANALYSIS': 10695,\n",
       "         'PRE_RELIED': 1431,\n",
       "         'RATIO': 674,\n",
       "         'RPC': 1081,\n",
       "         'ISSUE': 367,\n",
       "         'STA': 481,\n",
       "         'PRE_NOT_RELIED': 158})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training through 1 document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = label_encode(list(set(labels)))\n",
    "# del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.transform([\"ISSUE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARG_RESPONDENT'], dtype='<U14')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_document = data[0]['annotations'][0]['result']\n",
    "len(train_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model : object, loss_fn : object,\n",
    "          inp : torch.TensorType, target : torch.TensorType) -> float:\n",
    "    \"\"\"\n",
    "    Train the decoder model for a single step using the given input and target sequences.\n",
    "\n",
    "    Args:\n",
    "        decoder (object): The decoder model to be trained.\n",
    "        decoder_optimizer (object): The optimizer for updating the decoder's parameters.\n",
    "        inp (torch.TensorType): The input sequence tensor.\n",
    "        target (torch.TensorType): The target sequence tensor.\n",
    "\n",
    "    Returns:\n",
    "        float: The normalized loss for the current training step, averaged over the sequence length.\n",
    "    \"\"\"\n",
    "    output = model(inp).unsqueeze(0)\n",
    "    # print(f\"output size: {output.size()}, target_size: {target.size()} \")\n",
    "    loss = loss_fn(output, target)\n",
    "    \n",
    "    out = torch.argmax(output).item()\n",
    "    prediction = label_encoder.inverse_transform([out])[0]\n",
    "    target_str = label_encoder.inverse_transform(target)[0]\n",
    "    print(f\"Prediction: {prediction}, Target: {target_str}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12001/547678469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_triplet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0msent_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent2wordemb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAX_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_sent_tok_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0msent_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/legaleval-subtask-a/utils.py\u001b[0m in \u001b[0;36msent2wordemb\u001b[0;34m(sentence, MAX_LEN)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msent2wordemb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3850\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3851\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3852\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3853\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3854\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4225\u001b[0m                 \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4226\u001b[0m             )\n\u001b[0;32m-> 4227\u001b[0;31m             \u001b[0merror_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_state_dict_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4228\u001b[0m             \u001b[0moffload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4229\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;31m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;31m# it's safe to delete it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    621\u001b[0m                             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                     error_msgs.append(f'While copying the parameter named \"{key}\", '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_sent_tok_len = 128\n",
    "\n",
    "for doc_index, doc in enumerate(data):\n",
    "    if doc_index > 6:\n",
    "        break\n",
    "    train_document = doc['annotations'][0]['result']\n",
    "    # print(len(train_document))\n",
    "    if train_document != []:\n",
    "        for entry_index, entry in enumerate(train_document):\n",
    "            sent_triplet = []\n",
    "            sent_tensor = torch.Tensor()\n",
    "            if entry_index == 0: # for start of document duplicate 1st sentence\n",
    "                sent_triplet.append(train_document[entry_index]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index+1]['value']['text'])\n",
    "            elif entry_index == len(train_document) - 1: # for end of document duplicate last sentence\n",
    "                sent_triplet.append(train_document[entry_index-1]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index]['value']['text'])\n",
    "            else:\n",
    "                sent_triplet.append(train_document[entry_index-1]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index]['value']['text'])\n",
    "                sent_triplet.append(train_document[entry_index+1]['value']['text'])\n",
    "                \n",
    "            for sent in sent_triplet:\n",
    "                sent_emb = sent2wordemb(sent,MAX_LEN = max_sent_tok_len) \n",
    "                sent_tensor = torch.cat((sent_tensor,sent_emb),dim=0)\n",
    "                \n",
    "            target_encoded = torch.from_numpy(label_encoder.transform(entry['value']['labels'])).long()\n",
    "            \n",
    "            save_encoded(sent_tensor, '../train_document/doc' + str(doc_index), \"embed_\" + str(entry_index))\n",
    "            save_encoded(target_encoded, '../train_document/doc' + str(doc_index), \"target_\" + str(entry_index))\n",
    "    #         # print(f\"{index} input size: {sent_tensor.size()} target size: {target_encoded.size()}\")\n",
    "    #     print(f\"Doc {doc_index} embedded and saved!\")\n",
    "    # training tensor --> sent_tensor\n",
    "    # training target --> target_encoded\n",
    "    \n",
    "    # loss = train(model,model_optimizer,sent_tensor,target_encoded)\n",
    "    # print(loss)\n",
    "    # all_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_encoded('../train_document/doc' + str(0), \"target_\" + str(31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_BiLSTM(\n",
      "  (word_conv): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 1), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (sent_conv): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bilstm): LSTM(768, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=13, bias=True)\n",
      "    (5): Softmax(dim=0)\n",
      "  )\n",
      ")\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# model_CNN = CNN(word_kernel_size = (3,1))\n",
    "# model_BiLSTM = BiLSTM(num_layers = 4)\n",
    "# CNN_optimizer = torch.optim.Adam(model_CNN.parameters(),lr=0.005)\n",
    "# BiLSTM_optimizer = torch.optim.Adam(model_BiLSTM.parameters(),lr=0.005)\n",
    "model = CNN_BiLSTM(word_kernel_size= (3,1), dropout= 0.1, num_layers= 4,hidden_size= 128)\n",
    "model_opt = torch.optim.RMSprop(model.parameters(), lr= 0.0002)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n",
    "print(model_opt)\n",
    "print(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: NONE, Target: PREAMBLE, Loss: 2.567845582962036\n",
      "document number: 0, sentence number: 0\n",
      "Prediction: PREAMBLE, Target: PREAMBLE, Loss: 2.55366849899292\n",
      "document number: 0, sentence number: 1\n",
      "Prediction: PREAMBLE, Target: PREAMBLE, Loss: 2.5211939811706543\n",
      "document number: 0, sentence number: 2\n",
      "Prediction: PREAMBLE, Target: PREAMBLE, Loss: 2.2871458530426025\n",
      "document number: 0, sentence number: 3\n",
      "Prediction: PREAMBLE, Target: NONE, Loss: 2.6471188068389893\n",
      "document number: 0, sentence number: 4\n",
      "Prediction: PREAMBLE, Target: FAC, Loss: 2.632453441619873\n",
      "document number: 0, sentence number: 5\n",
      "Prediction: PREAMBLE, Target: FAC, Loss: 2.548501968383789\n",
      "document number: 0, sentence number: 6\n",
      "Prediction: FAC, Target: FAC, Loss: 2.1857118606567383\n",
      "document number: 0, sentence number: 7\n",
      "Prediction: FAC, Target: FAC, Loss: 1.8135894536972046\n",
      "document number: 0, sentence number: 8\n",
      "Prediction: FAC, Target: FAC, Loss: 1.7100310325622559\n",
      "document number: 0, sentence number: 9\n",
      "Prediction: FAC, Target: FAC, Loss: 1.6971385478973389\n",
      "document number: 0, sentence number: 10\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688239574432373\n",
      "document number: 0, sentence number: 11\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6881771087646484\n",
      "document number: 0, sentence number: 12\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6881184577941895\n",
      "document number: 0, sentence number: 13\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6880486011505127\n",
      "document number: 0, sentence number: 14\n",
      "Prediction: FAC, Target: FAC, Loss: 1.6955589056015015\n",
      "document number: 0, sentence number: 15\n",
      "Prediction: FAC, Target: FAC, Loss: 1.6934340000152588\n",
      "document number: 0, sentence number: 16\n",
      "Prediction: FAC, Target: FAC, Loss: 1.692291021347046\n",
      "document number: 0, sentence number: 17\n",
      "Prediction: FAC, Target: FAC, Loss: 1.691611647605896\n",
      "document number: 0, sentence number: 18\n",
      "Prediction: FAC, Target: FAC, Loss: 1.6911184787750244\n",
      "document number: 0, sentence number: 19\n",
      "Prediction: FAC, Target: RLC, Loss: 2.6888508796691895\n",
      "document number: 0, sentence number: 20\n",
      "Prediction: FAC, Target: RLC, Loss: 2.6888461112976074\n",
      "document number: 0, sentence number: 21\n",
      "Prediction: FAC, Target: RLC, Loss: 2.68884015083313\n",
      "document number: 0, sentence number: 22\n",
      "Prediction: FAC, Target: RLC, Loss: 2.6888341903686523\n",
      "document number: 0, sentence number: 23\n",
      "Prediction: FAC, Target: FAC, Loss: 1.6909592151641846\n",
      "document number: 0, sentence number: 24\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688720226287842\n",
      "document number: 0, sentence number: 25\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688704013824463\n",
      "document number: 0, sentence number: 26\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688685655593872\n",
      "document number: 0, sentence number: 27\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.6886661052703857\n",
      "document number: 0, sentence number: 28\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688647508621216\n",
      "document number: 0, sentence number: 29\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688621759414673\n",
      "document number: 0, sentence number: 30\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688598871231079\n",
      "document number: 0, sentence number: 31\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.6885693073272705\n",
      "document number: 0, sentence number: 32\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688540458679199\n",
      "document number: 0, sentence number: 33\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.688506603240967\n",
      "document number: 0, sentence number: 34\n",
      "Prediction: FAC, Target: ARG_PETITIONER, Loss: 2.6884589195251465\n",
      "document number: 0, sentence number: 35\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6886510848999023\n",
      "document number: 0, sentence number: 36\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688629150390625\n",
      "document number: 0, sentence number: 37\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688608407974243\n",
      "document number: 0, sentence number: 38\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6885836124420166\n",
      "document number: 0, sentence number: 39\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6885576248168945\n",
      "document number: 0, sentence number: 40\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6885271072387695\n",
      "document number: 0, sentence number: 41\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6884968280792236\n",
      "document number: 0, sentence number: 42\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6884546279907227\n",
      "document number: 0, sentence number: 43\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.6884002685546875\n",
      "document number: 0, sentence number: 44\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688361644744873\n",
      "document number: 0, sentence number: 45\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688300609588623\n",
      "document number: 0, sentence number: 46\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688234567642212\n",
      "document number: 0, sentence number: 47\n",
      "Prediction: FAC, Target: ARG_RESPONDENT, Loss: 2.688157796859741\n",
      "document number: 0, sentence number: 48\n",
      "Prediction: FAC, Target: ANALYSIS, Loss: 2.688291549682617\n",
      "document number: 0, sentence number: 49\n",
      "Prediction: FAC, Target: ANALYSIS, Loss: 2.6882424354553223\n",
      "document number: 0, sentence number: 50\n",
      "Prediction: FAC, Target: ANALYSIS, Loss: 2.6881775856018066\n",
      "document number: 0, sentence number: 51\n",
      "Prediction: FAC, Target: ANALYSIS, Loss: 2.688110589981079\n",
      "document number: 0, sentence number: 52\n",
      "Prediction: FAC, Target: ANALYSIS, Loss: 2.6880290508270264\n",
      "document number: 0, sentence number: 53\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6878933906555176\n",
      "document number: 0, sentence number: 54\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6877851486206055\n",
      "document number: 0, sentence number: 55\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6876440048217773\n",
      "document number: 0, sentence number: 56\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6874866485595703\n",
      "document number: 0, sentence number: 57\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6872897148132324\n",
      "document number: 0, sentence number: 58\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6870594024658203\n",
      "document number: 0, sentence number: 59\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6867494583129883\n",
      "document number: 0, sentence number: 60\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.686368227005005\n",
      "document number: 0, sentence number: 61\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6859047412872314\n",
      "document number: 0, sentence number: 62\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.685317039489746\n",
      "document number: 0, sentence number: 63\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6845102310180664\n",
      "document number: 0, sentence number: 64\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6833600997924805\n",
      "document number: 0, sentence number: 65\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6817383766174316\n",
      "document number: 0, sentence number: 66\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6792399883270264\n",
      "document number: 0, sentence number: 67\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.675316333770752\n",
      "document number: 0, sentence number: 68\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.666621208190918\n",
      "document number: 0, sentence number: 69\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.6460344791412354\n",
      "document number: 0, sentence number: 70\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.5969293117523193\n",
      "document number: 0, sentence number: 71\n",
      "Prediction: FAC, Target: PRE_RELIED, Loss: 2.454352378845215\n",
      "document number: 0, sentence number: 72\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.2267377376556396\n",
      "document number: 0, sentence number: 73\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.9855962991714478\n",
      "document number: 0, sentence number: 74\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.831895351409912\n",
      "document number: 0, sentence number: 75\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7528241872787476\n",
      "document number: 0, sentence number: 76\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7160937786102295\n",
      "document number: 0, sentence number: 77\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7052240371704102\n",
      "document number: 0, sentence number: 78\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.6989192962646484\n",
      "document number: 0, sentence number: 79\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6880862712860107\n",
      "document number: 0, sentence number: 80\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6880836486816406\n",
      "document number: 0, sentence number: 81\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.688044786453247\n",
      "document number: 0, sentence number: 82\n",
      "Prediction: PRE_RELIED, Target: RATIO, Loss: 2.6857831478118896\n",
      "document number: 0, sentence number: 83\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.687863826751709\n",
      "document number: 0, sentence number: 84\n",
      "Prediction: PRE_RELIED, Target: RPC, Loss: 2.687466621398926\n",
      "document number: 0, sentence number: 85\n",
      "Prediction: PRE_RELIED, Target: RPC, Loss: 2.6873767375946045\n",
      "document number: 0, sentence number: 86\n",
      "Prediction: PRE_RELIED, Target: RPC, Loss: 2.687279224395752\n",
      "document number: 0, sentence number: 87\n",
      "Prediction: PRE_RELIED, Target: RPC, Loss: 2.6871743202209473\n",
      "document number: 0, sentence number: 88\n",
      "Prediction: PRE_RELIED, Target: RPC, Loss: 2.68704891204834\n",
      "document number: 0, sentence number: 89\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.6870977878570557\n",
      "document number: 0, sentence number: 90\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6863207817077637\n",
      "document number: 1, sentence number: 0\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6859242916107178\n",
      "document number: 1, sentence number: 1\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.685671806335449\n",
      "document number: 1, sentence number: 2\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6852097511291504\n",
      "document number: 1, sentence number: 3\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6846699714660645\n",
      "document number: 1, sentence number: 4\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.684011936187744\n",
      "document number: 1, sentence number: 5\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.683218002319336\n",
      "document number: 1, sentence number: 6\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6822240352630615\n",
      "document number: 1, sentence number: 7\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.6837286949157715\n",
      "document number: 1, sentence number: 8\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.6764607429504395\n",
      "document number: 1, sentence number: 9\n",
      "Prediction: PRE_RELIED, Target: ISSUE, Loss: 2.6835291385650635\n",
      "document number: 1, sentence number: 10\n",
      "Prediction: PRE_RELIED, Target: ISSUE, Loss: 2.6831955909729004\n",
      "document number: 1, sentence number: 11\n",
      "Prediction: PRE_RELIED, Target: ISSUE, Loss: 2.6826586723327637\n",
      "document number: 1, sentence number: 12\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.67922043800354\n",
      "document number: 1, sentence number: 13\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.6769213676452637\n",
      "document number: 1, sentence number: 14\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.6733226776123047\n",
      "document number: 1, sentence number: 15\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.666879177093506\n",
      "document number: 1, sentence number: 16\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.653022527694702\n",
      "document number: 1, sentence number: 17\n",
      "Prediction: PRE_RELIED, Target: ARG_PETITIONER, Loss: 2.6609573364257812\n",
      "document number: 1, sentence number: 18\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.590177059173584\n",
      "document number: 1, sentence number: 19\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.644775629043579\n",
      "document number: 1, sentence number: 20\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6408941745758057\n",
      "document number: 1, sentence number: 21\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.635918378829956\n",
      "document number: 1, sentence number: 22\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.628420829772949\n",
      "document number: 1, sentence number: 23\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6144542694091797\n",
      "document number: 1, sentence number: 24\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.5830092430114746\n",
      "document number: 1, sentence number: 25\n",
      "Prediction: PREAMBLE, Target: RLC, Loss: 2.5074145793914795\n",
      "document number: 1, sentence number: 26\n",
      "Prediction: RLC, Target: RLC, Loss: 2.3739380836486816\n",
      "document number: 1, sentence number: 27\n",
      "Prediction: RLC, Target: RLC, Loss: 2.1963086128234863\n",
      "document number: 1, sentence number: 28\n",
      "Prediction: RLC, Target: RLC, Loss: 1.9933249950408936\n",
      "document number: 1, sentence number: 29\n",
      "Prediction: RLC, Target: RLC, Loss: 1.8491299152374268\n",
      "document number: 1, sentence number: 30\n",
      "Prediction: RLC, Target: RLC, Loss: 1.767685890197754\n",
      "document number: 1, sentence number: 31\n",
      "Prediction: RLC, Target: RLC, Loss: 1.7221890687942505\n",
      "document number: 1, sentence number: 32\n",
      "Prediction: RLC, Target: RLC, Loss: 1.7065162658691406\n",
      "document number: 1, sentence number: 33\n",
      "Prediction: RLC, Target: RLC, Loss: 1.7008136510849\n",
      "document number: 1, sentence number: 34\n",
      "Prediction: RLC, Target: RLC, Loss: 1.6978888511657715\n",
      "document number: 1, sentence number: 35\n",
      "Prediction: RLC, Target: RLC, Loss: 1.696101188659668\n",
      "document number: 1, sentence number: 36\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6883203983306885\n",
      "document number: 1, sentence number: 37\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.688298463821411\n",
      "document number: 1, sentence number: 38\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6882805824279785\n",
      "document number: 1, sentence number: 39\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6882591247558594\n",
      "document number: 1, sentence number: 40\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6882388591766357\n",
      "document number: 1, sentence number: 41\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6882171630859375\n",
      "document number: 1, sentence number: 42\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.688192367553711\n",
      "document number: 1, sentence number: 43\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6881682872772217\n",
      "document number: 1, sentence number: 44\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.688142776489258\n",
      "document number: 1, sentence number: 45\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.68811297416687\n",
      "document number: 1, sentence number: 46\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6880874633789062\n",
      "document number: 1, sentence number: 47\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.68805193901062\n",
      "document number: 1, sentence number: 48\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6880249977111816\n",
      "document number: 1, sentence number: 49\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.687988758087158\n",
      "document number: 1, sentence number: 50\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6879515647888184\n",
      "document number: 1, sentence number: 51\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6879162788391113\n",
      "document number: 1, sentence number: 52\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6878774166107178\n",
      "document number: 1, sentence number: 53\n",
      "Prediction: RLC, Target: PRE_RELIED, Loss: 2.6865291595458984\n",
      "document number: 1, sentence number: 54\n",
      "Prediction: RLC, Target: PRE_RELIED, Loss: 2.6863341331481934\n",
      "document number: 1, sentence number: 55\n",
      "Prediction: RLC, Target: PRE_RELIED, Loss: 2.686098098754883\n",
      "document number: 1, sentence number: 56\n",
      "Prediction: RLC, Target: PRE_RELIED, Loss: 2.6857011318206787\n",
      "document number: 1, sentence number: 57\n",
      "Prediction: RLC, Target: PRE_RELIED, Loss: 2.685417652130127\n",
      "document number: 1, sentence number: 58\n",
      "Prediction: RLC, Target: RATIO, Loss: 2.682492733001709\n",
      "document number: 1, sentence number: 59\n",
      "Prediction: RLC, Target: RATIO, Loss: 2.680537462234497\n",
      "document number: 1, sentence number: 60\n",
      "Prediction: RLC, Target: RATIO, Loss: 2.6773440837860107\n",
      "document number: 1, sentence number: 61\n",
      "Prediction: RLC, Target: RATIO, Loss: 2.671504020690918\n",
      "document number: 1, sentence number: 62\n",
      "Prediction: RLC, Target: RATIO, Loss: 2.6590399742126465\n",
      "document number: 1, sentence number: 63\n",
      "Prediction: RLC, Target: ANALYSIS, Loss: 2.6789069175720215\n",
      "document number: 1, sentence number: 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6773/657080183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msent_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_encoded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../train_document/doc'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embed_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_encoded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../train_document/doc'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# output = model_CNN(sent_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# output = model_BiLSTM(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6773/3587102557.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, model_optimizer, loss_fn, inp, target)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnormalized\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraged\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# print(f\"output size: {output.size()}, target_size: {target.size()} \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/legaleval-subtask-a/models/CNN_BiLSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# out, (hidden,cell) = self.bilstm(x, (hidden, cell))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# all_losses = []\n",
    "# for doc_index, doc in enumerate(data):\n",
    "#     if doc_index > 3:\n",
    "#         break\n",
    "#     train_document = doc['annotations'][0]['result']\n",
    "#     for index in range(0, len(train_document)):\n",
    "#         # training tensor --> sent_tensor\n",
    "#         # training target --> target_encoded\n",
    "        \n",
    "#         sent_tensor = load_encoded('../train_document/doc' + str(doc_index), \"embed_\" + str(index))\n",
    "#         target_encoded = load_encoded('../train_document/doc' + str(doc_index), \"target_\" + str(index))\n",
    "#         loss = train(model,model_opt,loss_function,sent_tensor,target_encoded)\n",
    "#         # output = model_CNN(sent_tensor)\n",
    "#         # output = model_BiLSTM(output)\n",
    "#         # output = model(sent_tensor)\n",
    "#         # loss = loss_function(output.unsqueeze(0), target_encoded.squeeze())\n",
    "        \n",
    "#         # out = torch.zeros_like(output)\n",
    "#         # out[torch.argmax(output).item()] = 1.\n",
    "#         # prediction = label_encoder.inverse_transform(out.unsqueeze(0))[0]\n",
    "#         # target_str = label_encoder.inverse_transform(target_encoded)[0]\n",
    "#         # print(f\"Prediction: {prediction}, Target: {target_str}\")\n",
    "#         # loss.backward()\n",
    "#         # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "#         # model_opt.step()\n",
    "#         # model_opt.zero_grad()\n",
    "        \n",
    "#         print(f\"document number: {doc_index}, sentence number: {index}\")\n",
    "#         all_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.567145586013794\n",
      "Prediction: ARG_RESPONDENT, Target: PRE_RELIED, Loss: 2.561821460723877\n",
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.567192316055298\n",
      "Prediction: ARG_RESPONDENT, Target: FAC, Loss: 2.5656728744506836\n",
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.567016363143921\n",
      "Prediction: ARG_RESPONDENT, Target: PRE_RELIED, Loss: 2.561906337738037\n",
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.566987991333008\n",
      "Prediction: ARG_RESPONDENT, Target: ARG_PETITIONER, Loss: 2.567244052886963\n",
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.566970109939575\n",
      "Prediction: ARG_RESPONDENT, Target: ANALYSIS, Loss: 2.566925287246704\n",
      "epoch: 0, loss: 2.5658881664276123\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5557687282562256\n",
      "Prediction: PRE_RELIED, Target: NONE, Loss: 2.5802814960479736\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5556271076202393\n",
      "Prediction: PRE_RELIED, Target: ARG_RESPONDENT, Loss: 2.5649328231811523\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.538256883621216\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.538411855697632\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.537943124771118\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5561232566833496\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.556209087371826\n",
      "Prediction: PRE_RELIED, Target: ARG_RESPONDENT, Loss: 2.564913034439087\n",
      "epoch: 1, loss: 2.55484676361084\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.3802390098571777\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5242719650268555\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.584324836730957\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.599663019180298\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.599702835083008\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.5884201526641846\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.5884318351745605\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5247585773468018\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5244393348693848\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 2.3821165561676025\n",
      "epoch: 2, loss: 2.529636859893799\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5938267707824707\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.8259986639022827\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.8244892358779907\n",
      "Prediction: PRE_RELIED, Target: ARG_RESPONDENT, Loss: 2.6633496284484863\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.5940728187561035\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6626932621002197\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.8248045444488525\n",
      "Prediction: PRE_RELIED, Target: STA, Loss: 2.66909122467041\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6664721965789795\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6625568866729736\n",
      "epoch: 3, loss: 2.398735523223877\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.6884660720825195\n",
      "Prediction: PRE_RELIED, Target: RATIO, Loss: 2.688455581665039\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.688293218612671\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6884329319000244\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.6884608268737793\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6882989406585693\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.6934937238693237\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.685011386871338\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.68502140045166\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6850178241729736\n",
      "epoch: 4, loss: 2.587895154953003\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.687105655670166\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6761298179626465\n",
      "Prediction: PRE_RELIED, Target: ARG_RESPONDENT, Loss: 2.686872959136963\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.687286615371704\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7021510601043701\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6867523193359375\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.687282085418701\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.687094211578369\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.686746597290039\n",
      "Prediction: PRE_RELIED, Target: ISSUE, Loss: 2.687216281890869\n",
      "epoch: 5, loss: 2.587463617324829\n",
      "Prediction: PRE_RELIED, Target: ISSUE, Loss: 2.6844005584716797\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7231276035308838\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.684476852416992\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6544528007507324\n",
      "Prediction: PRE_RELIED, Target: RLC, Loss: 2.6830036640167236\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6547679901123047\n",
      "Prediction: PRE_RELIED, Target: PRE_RELIED, Loss: 1.7230838537216187\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.654576539993286\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.654568672180176\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.6546621322631836\n",
      "epoch: 6, loss: 2.477112293243408\n",
      "Prediction: PRE_RELIED, Target: STA, Loss: 2.6633567810058594\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.4588489532470703\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.459028720855713\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6571264266967773\n",
      "Prediction: PRE_RELIED, Target: FAC, Loss: 2.6645331382751465\n",
      "Prediction: PRE_RELIED, Target: ARG_PETITIONER, Loss: 2.659423828125\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.4587621688842773\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.4589130878448486\n",
      "Prediction: PRE_RELIED, Target: ANALYSIS, Loss: 2.458733081817627\n",
      "Prediction: PRE_RELIED, Target: PREAMBLE, Loss: 2.6571426391601562\n",
      "epoch: 7, loss: 2.559587001800537\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 2.068620204925537\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 2.0689451694488525\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6541101932525635\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.4095990657806396\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 2.070791482925415\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6210579872131348\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 2.0691416263580322\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 2.0687739849090576\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6332297325134277\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.65564227104187\n",
      "epoch: 8, loss: 2.331990957260132\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.673494815826416\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.6720211505889893\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.673485517501831\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.645815372467041\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.8220893144607544\n",
      "Prediction: ANALYSIS, Target: STA, Loss: 2.6722426414489746\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6734812259674072\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.821964979171753\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.666748285293579\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.821928858757019\n",
      "epoch: 9, loss: 2.4143271446228027\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.757043719291687\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6434786319732666\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.680736780166626\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.674449920654297\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.662675380706787\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7569032907485962\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6806163787841797\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6806087493896484\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7570054531097412\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.64342999458313\n",
      "epoch: 10, loss: 2.3936946392059326\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.681577205657959\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.745537519454956\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6815619468688965\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.66979718208313\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6698031425476074\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6820602416992188\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.681574583053589\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7455500364303589\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.682000160217285\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7455180883407593\n",
      "epoch: 11, loss: 2.398498058319092\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6824381351470947\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7293511629104614\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.680248260498047\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.683926820755005\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6802244186401367\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.660816192626953\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7293970584869385\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6609277725219727\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6609690189361572\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.671933174133301\n",
      "epoch: 12, loss: 2.484022855758667\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7380290031433105\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7381197214126587\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.678974151611328\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7381588220596313\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6500160694122314\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7381705045700073\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.678983688354492\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7380551099777222\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.671579360961914\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.678981304168701\n",
      "epoch: 13, loss: 2.204906702041626\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6847026348114014\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7164790630340576\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.685544490814209\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6855359077453613\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7165004014968872\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.684696912765503\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.716498613357544\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6846961975097656\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6855454444885254\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.683863878250122\n",
      "epoch: 14, loss: 2.39440655708313\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6806321144104004\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7104246616363525\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7104767560958862\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.672832489013672\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.684218645095825\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.686328411102295\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6728549003601074\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7104744911193848\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7104241847991943\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7104754447937012\n",
      "epoch: 15, loss: 2.1949143409729004\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6764767169952393\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6764845848083496\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.704965353012085\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6830220222473145\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.686068296432495\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6855437755584717\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.686943292617798\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.687030553817749\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.676487922668457\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.676494836807251\n",
      "epoch: 16, loss: 2.583951473236084\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7105215787887573\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.670332908630371\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7105320692062378\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.682084083557129\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6703298091888428\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6703290939331055\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7105534076690674\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.685751438140869\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6852409839630127\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6863269805908203\n",
      "epoch: 17, loss: 2.388200283050537\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6676392555236816\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6676225662231445\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6861412525177\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.686119794845581\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6861283779144287\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6851673126220703\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.711983323097229\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.667630195617676\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.685588836669922\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6861252784729004\n",
      "epoch: 18, loss: 2.583014726638794\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6843204498291016\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.684943199157715\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7215945720672607\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7215015888214111\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.655985116958618\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6843175888061523\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.683943510055542\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.683285713195801\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6849403381347656\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.683281660079956\n",
      "epoch: 19, loss: 2.488811492919922\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6814208030700684\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7220304012298584\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.68477725982666\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.722029685974121\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.683223247528076\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6814005374908447\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7220392227172852\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.722002625465393\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.684884548187256\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.683209180831909\n",
      "epoch: 20, loss: 2.298701763153076\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6864724159240723\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7092150449752808\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.686405658721924\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6830742359161377\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7092888355255127\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7092875242233276\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7092597484588623\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6830897331237793\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6864774227142334\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7092609405517578\n",
      "epoch: 21, loss: 2.197183132171631\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7023764848709106\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7023816108703613\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.687356948852539\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6873512268066406\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.687016248703003\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7023911476135254\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6866838932037354\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7023897171020508\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6873576641082764\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.7023760080337524\n",
      "epoch: 22, loss: 2.194768190383911\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6987673044204712\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6809325218200684\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.687286376953125\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.698813796043396\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.680929660797119\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.685560703277588\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6988130807876587\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6809520721435547\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.687793254852295\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6988071203231812\n",
      "epoch: 23, loss: 2.289865493774414\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.698415756225586\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6874003410339355\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6984217166900635\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6871018409729004\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6871042251586914\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6984206438064575\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.685878276824951\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6984398365020752\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6984307765960693\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.698420763015747\n",
      "epoch: 24, loss: 2.093803644180298\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6961339712142944\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683140754699707\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6961475610733032\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6881656646728516\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.687788963317871\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6864850521087646\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688162326812744\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6831462383270264\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6961431503295898\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.696138620376587\n",
      "epoch: 25, loss: 2.2901451587677\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688225269317627\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6876726150512695\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.695671796798706\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6834802627563477\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683490514755249\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956579685211182\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6880722045898438\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688072919845581\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956549882888794\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683474063873291\n",
      "epoch: 26, loss: 2.388947010040283\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.687674045562744\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6957827806472778\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6831917762756348\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6881887912750244\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683176040649414\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6957825422286987\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6957736015319824\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6868019104003906\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6831917762756348\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6957756280899048\n",
      "epoch: 27, loss: 2.289533853530884\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956254243850708\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683197498321533\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956043243408203\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956133842468262\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6882336139678955\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.686946392059326\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6831865310668945\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6869425773620605\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6956079006195068\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6879403591156006\n",
      "epoch: 28, loss: 2.2898898124694824\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6878058910369873\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6881468296051025\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.687056064605713\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.688279390335083\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6882786750793457\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6952658891677856\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.68827748298645\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6952601671218872\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.688279867172241\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.6882662773132324\n",
      "epoch: 29, loss: 2.4894919395446777\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.695062518119812\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6882855892181396\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6883037090301514\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.695052146911621\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6950669288635254\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6883063316345215\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6882872581481934\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.683746814727783\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.695060133934021\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6883063316345215\n",
      "epoch: 30, loss: 2.2905478477478027\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6944981813430786\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688378095626831\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.688361406326294\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6945096254348755\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.687948703765869\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6872661113739014\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.694488763809204\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6944963932037354\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.684246301651001\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.687950611114502\n",
      "epoch: 31, loss: 2.2902143001556396\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6884360313415527\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6940664052963257\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6940534114837646\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.694055438041687\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.6884264945983887\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6940529346466064\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.694052815437317\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6940484046936035\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6846859455108643\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688438653945923\n",
      "epoch: 32, loss: 2.0914318561553955\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.688188076019287\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6853857040405273\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6876513957977295\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688537359237671\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.688187599182129\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.687652826309204\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.688530921936035\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.685389518737793\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.688539505004883\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.687650680541992\n",
      "epoch: 33, loss: 2.6875712871551514\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.68806791305542\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6884632110595703\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688361883163452\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938538551330566\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938536167144775\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6874661445617676\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938495635986328\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938588619232178\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938620805740356\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6938666105270386\n",
      "epoch: 34, loss: 2.091550350189209\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.68858003616333\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692969560623169\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692967176437378\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.688567638397217\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.685731887817383\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6929601430892944\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6929680109024048\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6929688453674316\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6885790824890137\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688495635986328\n",
      "epoch: 35, loss: 2.190478801727295\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6878368854522705\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6885552406311035\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6860673427581787\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.687835693359375\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6885554790496826\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6860671043395996\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.686065196990967\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925805807113647\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925833225250244\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6883292198181152\n",
      "epoch: 36, loss: 2.488447666168213\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6858322620391846\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6882970333099365\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6885931491851807\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6886019706726074\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6927924156188965\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6927882432937622\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.687791347503662\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6927889585494995\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6877872943878174\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6885247230529785\n",
      "epoch: 37, loss: 2.3893799781799316\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6859331130981445\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.6884450912475586\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.688615322113037\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6926956176757812\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6878044605255127\n",
      "Prediction: ANALYSIS, Target: STA, Loss: 2.6886096000671387\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692700982093811\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6859374046325684\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6926897764205933\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6926974058151245\n",
      "epoch: 38, loss: 2.2896130084991455\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.688633441925049\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688634157180786\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6878654956817627\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925394535064697\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.686046838760376\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925489902496338\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925554275512695\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692547082901001\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925501823425293\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6925499439239502\n",
      "epoch: 39, loss: 2.0906472206115723\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.688680410385132\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688624620437622\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.688681125640869\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692136526107788\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6886885166168213\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6884255409240723\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6884255409240723\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.68643856048584\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6921368837356567\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6921430826187134\n",
      "epoch: 40, loss: 2.3894379138946533\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.6886937618255615\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887006759643555\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.688445806503296\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.686514377593994\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6920416355133057\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6920405626296997\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6920398473739624\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.692037582397461\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6884450912475586\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.688561201095581\n",
      "epoch: 41, loss: 2.289752244949341\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691871166229248\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6881041526794434\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6884777545928955\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691877007484436\n",
      "Prediction: ANALYSIS, Target: RATIO, Loss: 2.6887221336364746\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688664436340332\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6918772459030151\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.688718795776367\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6884775161743164\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6866538524627686\n",
      "epoch: 42, loss: 2.3893444538116455\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6881251335144043\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6867151260375977\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6881237030029297\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6918150186538696\n",
      "Prediction: ANALYSIS, Target: RPC, Loss: 2.688600540161133\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6867175102233887\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887309551239014\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6887311935424805\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691812515258789\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6918127536773682\n",
      "epoch: 43, loss: 2.3891186714172363\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.688727378845215\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.688732385635376\n",
      "Prediction: ANALYSIS, Target: ISSUE, Loss: 2.688725709915161\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887316703796387\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691808819770813\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.688732385635376\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6918025016784668\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6918081045150757\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691805362701416\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.686720132827759\n",
      "epoch: 44, loss: 2.289759397506714\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887521743774414\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6881844997406006\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691656231880188\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6885292530059814\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6881818771362305\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6916544437408447\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691656231880188\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688699245452881\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887521743774414\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.691654086112976\n",
      "epoch: 45, loss: 2.2897720336914062\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914913654327393\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887731552124023\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914900541305542\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6887736320495605\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.6887705326080322\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.6887733936309814\n",
      "Prediction: ANALYSIS, Target: STA, Loss: 2.688770055770874\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6887736320495605\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6885592937469482\n",
      "Prediction: ANALYSIS, Target: NONE, Loss: 2.6887738704681396\n",
      "epoch: 46, loss: 2.48929500579834\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914457082748413\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6870663166046143\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.688730239868164\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688779830932617\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.69144868850708\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6870622634887695\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914440393447876\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.6885673999786377\n",
      "Prediction: ANALYSIS, Target: PRE_RELIED, Loss: 2.6870648860931396\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914445161819458\n",
      "epoch: 47, loss: 2.2893054485321045\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688783645629883\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6882731914520264\n",
      "Prediction: ANALYSIS, Target: ARG_PETITIONER, Loss: 2.6887805461883545\n",
      "Prediction: ANALYSIS, Target: RLC, Loss: 2.688577651977539\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6887359619140625\n",
      "Prediction: ANALYSIS, Target: ARG_RESPONDENT, Loss: 2.6887364387512207\n",
      "Prediction: ANALYSIS, Target: FAC, Loss: 2.688783645629883\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914108991622925\n",
      "Prediction: ANALYSIS, Target: PREAMBLE, Loss: 2.6882736682891846\n",
      "Prediction: ANALYSIS, Target: ANALYSIS, Loss: 1.6914151906967163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9844/1217131966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mavg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for epoch in range(100):\n",
    "    losses = []\n",
    "    for _ in range(10):\n",
    "        doc_num = random.randint(0,3)\n",
    "        file_num = random.randint(0,len(os.listdir(f'../train_document/doc{doc_num}/'))/2 - 1)\n",
    "        # print(doc_num, len(os.listdir(f'../train_document/doc{doc_num}/'))/2)\n",
    "        sent_tensor = load_encoded('../train_document/doc' + str(doc_num), \"embed_\" + str(file_num))\n",
    "        target_encoded = load_encoded('../train_document/doc' + str(doc_num), \"target_\" + str(file_num))\n",
    "        losses.append(train(model,loss_function,sent_tensor,target_encoded));\n",
    "    avg_loss = torch.stack(losses).mean()\n",
    "    avg_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    model_opt.step()\n",
    "    model_opt.zero_grad()\n",
    "    print(f\"epoch: {epoch}, loss: {avg_loss}\")\n",
    "    all_losses.append(avg_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_encoded('../train_document/doc' + str(0), \"target_\" + str(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd4a1a3e190>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,len(all_losses)),all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f29f4ba4fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,len(all_losses)),all_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
