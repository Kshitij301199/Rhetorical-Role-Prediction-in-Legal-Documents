{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(),'..')))\n",
    "from utils import Dataset_Reader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Save PyTorch model parameters to a file.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): PyTorch model to save.\n",
    "    - filepath (str): Filepath to save the model parameters.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model parameters saved to '{filepath}'\")\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Load PyTorch model parameters from a file.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): PyTorch model to load parameters into.\n",
    "    - filepath (str): Filepath to the saved model parameters.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    print(f\"Model parameters loaded from '{filepath}'\")\n",
    "    \n",
    "def save_tensor(tensor, dir, filename):\n",
    "    \"\"\"\n",
    "    Save PyTorch tensor to a file.\n",
    "\n",
    "    Args:\n",
    "    - tensor (torch.Tensor): PyTorch tensor to save.\n",
    "    - dir (str): Directory to save the tensor.\n",
    "    - filename (str): Filename to save the tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(os.path.join(dir)):\n",
    "        os.makedirs(os.path.join(dir))\n",
    "        \n",
    "    filepath = os.path.join(dir, filename)\n",
    "    torch.save(tensor, filepath)\n",
    "    print(f\"Tensor saved to '{filepath}'\")\n",
    "\n",
    "def load_tensor(filepath):\n",
    "    \"\"\"\n",
    "    Load PyTorch tensor from a file.\n",
    "\n",
    "    Args:\n",
    "    - filepath (str): Filepath to the saved tensor.\n",
    "\n",
    "    Returns:\n",
    "    - tensor (torch.Tensor): Loaded PyTorch tensor.\n",
    "    \"\"\"\n",
    "    tensor = torch.load(filepath)\n",
    "    # print(f\"Tensor loaded from '{filepath}'\")\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.json', 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "with open('../data/dev.json', 'r') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "TRAIN_data = Dataset_Reader(train_data)\n",
    "TEST_data = Dataset_Reader(test_data)\n",
    "print(len(TRAIN_data))\n",
    "# TRAIN_data_batched = DataLoader(TRAIN_data, batch_size = 5, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(documents, tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')):\n",
    "    \"\"\"\n",
    "    Generate the maximum length of each sentence in each document. This is necessary to make sure there is a fixed sentence-length \n",
    "    for each document before we pass the sentence embeddings through the model.\n",
    "\n",
    "    Returns: {document index: length of longest sentence}\n",
    "\n",
    "    \"\"\"\n",
    "    max_l_dict = {}\n",
    "    \n",
    "    for sentence in documents.texts:\n",
    "        size = []\n",
    "\n",
    "        inputs = tokenizer(sentence[2], return_tensors=\"pt\", truncation=True, padding=True, add_special_tokens= True)\n",
    "\n",
    "        size.append(inputs['input_ids'].size(1))\n",
    "        \n",
    "        max_l_dict[sentence[0]] = max(size)\n",
    "    \n",
    "    dict_keys = list(max_l_dict.keys())\n",
    "    reference_keys = list(range(len(documents)))  \n",
    "    for key in reference_keys:\n",
    "        if key not in dict_keys:\n",
    "            max_l_dict[key] = 0\n",
    "            \n",
    "    return max_l_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_data(data: Dataset, batch_size:int = 1) ->  Tuple[List,List,List]:\n",
    "    doc_idx = []\n",
    "    batched_texts = []\n",
    "    batched_labels = []\n",
    "    for start, stop in zip(range(0,len(data)-batch_size,batch_size), range(batch_size,len(data),batch_size)):\n",
    "        idxs = []\n",
    "        texts = []\n",
    "        labels = []\n",
    "        for idx in range(start,stop):\n",
    "            idxs.append(idx) \n",
    "            [texts.append(text) for text in data[idx]['text']]\n",
    "            [labels.append(label) for label in data[idx]['label']]\n",
    "        \n",
    "        doc_idx.append(idxs)\n",
    "        batched_texts.append(texts)\n",
    "        batched_labels.append(labels)\n",
    "    return doc_idx, batched_texts, batched_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lens_train = max_length(TRAIN_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idxs, batched_texts, batched_labels = get_batched_data(TRAIN_data, batch_size= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(target_variables : list) -> LabelEncoder:\n",
    "    \"\"\"\n",
    "    Encode target variables.\n",
    "    \n",
    "    Args:\n",
    "    - target_variables (list or array-like): List of target variable strings.\n",
    "    \n",
    "    Returns:\n",
    "    - lb (object): class object used to tranform and inverse transform.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(target_variables)\n",
    "    \n",
    "    return le\n",
    "\n",
    "def get_model_data(data:torch.utils.data.Dataset, encoder: LabelEncoder,\n",
    "                   tokenizer= BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "                   model= BertModel.from_pretrained('bert-base-uncased'),\n",
    "                   num_of_docs:int = None,\n",
    "                   ) -> Tuple[torch.TensorType, torch.TensorType]:\n",
    "    numerical_labels = encoder.transform(data.labels)\n",
    "    sent_emb = []\n",
    "    max_sent_length = 128\n",
    "    if num_of_docs is None:\n",
    "        for idx, sentence in enumerate(data.texts):\n",
    "            inputs = tokenizer(sentence[2].lower(),  return_tensors=\"pt\", truncation= True,\n",
    "                                padding='max_length', max_length = max_sent_length,\n",
    "                                add_special_tokens= True)\n",
    "            with torch.no_grad():\n",
    "                output = model(**inputs)\n",
    "            sent_emb.append(output.last_hidden_state[:,0,:])\n",
    "    else:\n",
    "        for idx, sentence in enumerate(data.texts):\n",
    "            if sentence[0] < num_of_docs:\n",
    "                inputs = tokenizer(sentence[2].lower(),  return_tensors=\"pt\", truncation= True,\n",
    "                                    padding='max_length', max_length = max_sent_length,\n",
    "                                    add_special_tokens= True)\n",
    "                with torch.no_grad():\n",
    "                    output = model(**inputs)\n",
    "                sent_emb.append(output.last_hidden_state[:,0,:]) \n",
    "        numerical_labels = numerical_labels[:len(sent_emb)]\n",
    "    x_train = np.zeros((len(sent_emb), 1, 768), dtype=float)\n",
    "    y_train = torch.from_numpy(numerical_labels)\n",
    "    for idx, sentence in enumerate(sent_emb):\n",
    "        x_train[idx] = sent_emb[idx]\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    print(f\"X_train size: {x_train.size()}\\tY_train size: {y_train.size()}\")\n",
    "    return x_train, y_train\n",
    "\n",
    "def get_model_data_batched(indexes:List, texts:List, labels:List, encoder:LabelEncoder,max_len_dict:Dict,\n",
    "                           tokenizer= BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "                           model= BertModel.from_pretrained('bert-base-uncased'),\n",
    "                           ) -> Tuple[torch.TensorType, torch.TensorType]:\n",
    "    numerical_labels = encoder.transform(labels)\n",
    "    sent_emb = []\n",
    "    for idx, sentence in enumerate(texts):\n",
    "        try:\n",
    "            max_sent_length = max([max_len_dict[i] for i in indexes])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        inputs = tokenizer(sentence.lower(),  return_tensors=\"pt\", truncation= True,\n",
    "                            padding='max_length', max_length = max_sent_length,\n",
    "                            add_special_tokens= True)\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "        sent_emb.append(output.last_hidden_state[:,0,:])\n",
    "    x_train = np.zeros((len(sent_emb), 1, 768), dtype=float)\n",
    "    y_train = torch.from_numpy(numerical_labels)\n",
    "    for idx, sentence in enumerate(sent_emb):\n",
    "        x_train[idx] = sent_emb[idx]\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    print(f\"X_train size: {x_train.size()}\\tY_train size: {y_train.size()}\")\n",
    "    return x_train, y_train    \n",
    "    \n",
    "\n",
    "list_of_targets = ['ISSUE', 'FAC', 'NONE', 'ARG_PETITIONER', 'PRE_NOT_RELIED', 'STA', 'RPC', 'ARG_RESPONDENT', 'PREAMBLE', 'ANALYSIS', 'RLC', 'PRE_RELIED', 'RATIO']\n",
    "label_encoder = label_encode(list_of_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size:int = 768,\n",
    "                hidden_size:int = 256,\n",
    "                num_layers:int = 2,\n",
    "                output_size:int = 13,\n",
    "                dropout:float = 0.1\n",
    "                ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.bilstm = nn.LSTM(input_size = input_size,\n",
    "                              hidden_size = hidden_size,\n",
    "                              num_layers = num_layers,\n",
    "                              bidirectional=True)\n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Dropout(p=dropout),\n",
    "                                   nn.Linear(hidden_size*2, 128),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(128, output_size),\n",
    "                                   nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        # Fully connected layers\n",
    "        out = self.dense(lstm_out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_emb, TRAIN_labels = get_model_data(data= TRAIN_data, encoder= label_encoder, num_of_docs= 10)\n",
    "# TEST_emb, TEST_labels = get_model_data(data= TEST_data, encoder= label_encoder,num_of_docs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, model, optimizer, loss_fc, num_epochs):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    model.train()\n",
    "    # print(f'{\"Starting Training\":-^100}')\n",
    "    for epoch in range(num_epochs+1):\n",
    "        output = model(x_train)\n",
    "        loss = loss_fc(output,y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if epoch%50 == 0:\n",
    "            acc = sum(output.argmax(dim=1) == y_train)/ output.size(0)\n",
    "            acc_list.append(acc)\n",
    "            print(f\"Epoch: {epoch} \\t Loss: {loss.item():.5f} \\t Accuracy: {acc*100:.2f}%\")\n",
    "            \n",
    "    return loss_list, acc_list\n",
    "            \n",
    "def test_accuracy(x_test, y_test, model):\n",
    "    model.eval()\n",
    "    output = model(x_test)\n",
    "    acc = sum(output.argmax(dim=1) == y_test)/ output.size(0)\n",
    "    print(f\"Test Accuracy {acc*100:.2f}%\")\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_highest_to_one(tensor):\n",
    "    max_val, max_idx = tensor.max(dim=1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(1, max_idx, 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_accuracy(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for each class based on a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    conf_matrix (numpy.ndarray): Confusion matrix.\n",
    "\n",
    "    Returns:\n",
    "    list: List of accuracies for each class.\n",
    "    \"\"\"\n",
    "    diagonal = np.diag(conf_matrix)\n",
    "\n",
    "    row_sums = conf_matrix.sum(axis=1)\n",
    "\n",
    "    accuracies = diagonal / row_sums.astype(float)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_f1_score(conf_matrix, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Calculate F1 score for each class based on a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    conf_matrix (numpy.ndarray): Confusion matrix.\n",
    "    epsilon (float): Smoothing term to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    list: List of F1 scores for each class.\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = np.diag(conf_matrix)\n",
    "    fp = conf_matrix.sum(axis=0) - tp\n",
    "    fn = conf_matrix.sum(axis=1) - tp\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, y_true, num_classes):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix for label encodings in PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    y_pred (torch.Tensor): Predicted labels tensor.\n",
    "    y_true (torch.Tensor): True labels tensor.\n",
    "    num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    #y_pred = set_highest_to_one(y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if y_pred.shape != y_true.shape:\n",
    "        raise ValueError(\"Shapes of predictions and true labels must match. y_pred shape: {} y_true shape: {}\".format(y_pred.shape, y_true.shape))\n",
    "\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "    y_true_np = y_true.cpu().numpy()\n",
    "\n",
    "    for pred, true in zip(y_pred_np, y_true_np):\n",
    "        conf_matrix[pred, true] += 1\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(parameters):\n",
    "    keys = parameters.keys()\n",
    "    values = parameters.values()\n",
    "    \n",
    "    combinations = list(product(*values))\n",
    "    \n",
    "    parameter_configurations = [{k: v for k, v in zip(keys, combination)} for combination in combinations]\n",
    "    \n",
    "    return parameter_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_test_split(size, training_data_size):\n",
    "    indices = np.arange(size)\n",
    "    np.random.shuffle(indices)\n",
    "    training_data_length = int(size * training_data_size)\n",
    "    training_data_indices = indices[:training_data_length]\n",
    "    test_data_indices = indices[training_data_length:]\n",
    "    return training_data_indices, test_data_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_value(item):\n",
    "    return item[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(test_emb, test_labels, model):\n",
    "    model.eval()\n",
    "    output = model(test_emb)\n",
    "    return confusion_matrix(output, test_labels, len(test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_train_test(parameters):\n",
    "    result = []\n",
    "    parameter_configs = grid_search(parameters)\n",
    "    \n",
    "    for config in parameter_configs:\n",
    "        batch_loss, batch_acc = [], []\n",
    "        model = BiLSTM(hidden_size=config['hidden_size'], num_layers=config['num_layers'], dropout=config['dropout'])\n",
    "        model_opt = torch.optim.Adam(model.parameters(), lr= config['learning_rate'])\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        print(\"Working with: \")\n",
    "        print(config)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "        print(f'{\"Starting Training\":-^100}')\n",
    "        model.train()\n",
    "        for epoch in range(config['epochs']):\n",
    "            # print(f\"Epoch {epoch}\")\n",
    "            for idx in tqdm(range(246)):\n",
    "                TRAIN_emb = load_tensor(filepath=f\"../train_document/doc_{idx}/embedding\")\n",
    "                TRAIN_labels = load_tensor(filepath=f\"../train_document/doc_{idx}/label\")\n",
    "                if TRAIN_emb.size(0) == 0:\n",
    "                    continue\n",
    "                output = model(TRAIN_emb)\n",
    "                loss = loss_function(output,TRAIN_labels)\n",
    "                \n",
    "                model_opt.zero_grad()\n",
    "                loss.backward()\n",
    "                model_opt.step()\n",
    "                \n",
    "            print(f\"Epoch: {epoch+1} \\t Loss: {loss.item():.5f}\")\n",
    "            batch_loss.append(loss.item())\n",
    "        \n",
    "        confusion_matrix = None\n",
    "        for i in range(29):\n",
    "            TEST_emb = load_tensor(filepath=f\"../test_document/doc_{i}/embedding\")\n",
    "            TEST_labels = load_tensor(filepath=f\"../test_document/doc_{i}/label\")\n",
    "            conf_matrix_helper = calculate_confusion_matrix(TEST_emb, TEST_labels, model)\n",
    "            if confusion_matrix:\n",
    "                confusion_matrix = np.add(confusion_matrix, conf_matrix_helper)\n",
    "            else:\n",
    "                confusion_matrix = conf_matrix_helper\n",
    "                \n",
    "        accuracies = class_accuracy(confusion_matrix)\n",
    "        f1_scores = class_f1_score(confusion_matrix)\n",
    "        average_accuracy = np.mean(accuracies)\n",
    "        average_f1 = np.mean(f1_scores)\n",
    "        \n",
    "        print(\"Accuracies: {accuracies} \\n Average acccuracy: {average_accuracy}\")\n",
    "        print(\"F1 Scores: {f1_scores} \\n Average F1: {average_f1}\")\n",
    "        \n",
    "        result.append((config, (average_accuracy, average_f1)))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with: \n",
      "{'epochs': 10, 'learning_rate': 0.0001, 'dropout': 0.0, 'hidden_size': 128, 'num_layers': 1}\n",
      "\n",
      "\n",
      "-----------------------------------------Starting Training------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:06<00:00, 39.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Loss: 2.32586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \t Loss: 2.32443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 45.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \t Loss: 2.30299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 45.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \t Loss: 2.25840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Loss: 2.25411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 46.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \t Loss: 2.25018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:06<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \t Loss: 2.23882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 41.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \t Loss: 2.22097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \t Loss: 1.95283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:05<00:00, 42.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t Loss: 2.01258\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes of predictions and true labels must match. y_pred shape: torch.Size([96, 13]) y_true shape: torch.Size([96])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m parameter_configs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      7\u001b[0m     }\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameter_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m max_accuracy_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(result, key\u001b[38;5;241m=\u001b[39mget_accuracy_value)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(max_accuracy_config)\n",
      "Cell \u001b[0;32mIn[25], line 38\u001b[0m, in \u001b[0;36mgrid_search_train_test\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     36\u001b[0m TEST_emb \u001b[38;5;241m=\u001b[39m load_tensor(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../test_document/doc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m TEST_labels \u001b[38;5;241m=\u001b[39m load_tensor(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../test_document/doc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/label\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m conf_matrix_helper \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m confusion_matrix:\n\u001b[1;32m     40\u001b[0m     confusion_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(confusion_matrix, conf_matrix_helper)\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mcalculate_confusion_matrix\u001b[0;34m(test_emb, test_labels, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m model(test_emb)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 18\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_pred, y_true, num_classes)\u001b[0m\n\u001b[1;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m set_highest_to_one(y_pred)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes of predictions and true labels must match. y_pred shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m y_true shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_pred\u001b[38;5;241m.\u001b[39mshape, y_true\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     20\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_classes, num_classes), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     22\u001b[0m y_pred_np \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes of predictions and true labels must match. y_pred shape: torch.Size([96, 13]) y_true shape: torch.Size([96])"
     ]
    }
   ],
   "source": [
    "parameter_configs = {\n",
    "    'epochs': [10, 20, 30],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'dropout': [0.0, 0.1, 0.2, 0.3],\n",
    "    'hidden_size': [128, 256, 512],\n",
    "    'num_layers': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "result = grid_search_train_test(parameter_configs)\n",
    "\n",
    "max_accuracy_config = max(result, key=get_accuracy_value)\n",
    "\n",
    "print(max_accuracy_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses, accs = train(TRAIN_emb,TRAIN_labels,model,model_opt,loss_function,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_emb, TEST_labels = get_model_data(data= TEST_data, encoder= label_encoder,num_of_docs= 5)\n",
    "# test_accuracy(TEST_emb, TEST_labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(dropout=0.0, num_layers=1)\n",
    "model_opt = torch.optim.Adam(model.parameters(), lr= 5e-5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------Starting Training------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:09<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Loss: 2.41102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \t Loss: 2.32699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \t Loss: 2.14745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:08<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \t Loss: 2.04829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:08<00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Loss: 2.06316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \t Loss: 2.05664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \t Loss: 2.08549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:08<00:00, 29.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \t Loss: 2.03122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \t Loss: 2.02196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \t Loss: 2.01100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \t Loss: 2.01911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \t Loss: 2.03949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \t Loss: 2.00497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \t Loss: 1.93509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \t Loss: 1.93260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 32.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \t Loss: 1.92965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \t Loss: 1.93059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \t Loss: 1.90713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 32.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \t Loss: 1.93041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:07<00:00, 31.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \t Loss: 2.05209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_loss, batch_acc = [], []\n",
    "# batch_counter = 0\n",
    "# random_doc_indexes = random.sample([i for i in range(len(batched_texts))],k=10)\n",
    "# print(random_doc_indexes)\n",
    "print(f'{\"Starting Training\":-^100}')\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    # print(f\"Epoch {epoch}\")\n",
    "    for idx in tqdm(range(246)):\n",
    "        TRAIN_emb = load_tensor(filepath=f\"../train_document/doc_{idx}/embedding\")\n",
    "        TRAIN_labels = load_tensor(filepath=f\"../train_document/doc_{idx}/label\")\n",
    "        if TRAIN_emb.size(0) == 0:\n",
    "            continue\n",
    "        output = model(TRAIN_emb)\n",
    "        loss = loss_function(output,TRAIN_labels)\n",
    "        \n",
    "        model_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        model_opt.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch+1} \\t Loss: {loss.item():.5f}\")\n",
    "    batch_loss.append(loss.item())\n",
    "\n",
    "    # # batch_counter += 1\n",
    "    # # print(f\"{f'BATCH NUMBER {batch_counter}':-^100}\")\n",
    "    #     TRAIN_emb = load_tensor(filepath=f\"../train_document/doc_{idx}/embedding\")\n",
    "    #     TRAIN_labels = load_tensor(filepath=f\"../train_document/doc_{idx}/label\")\n",
    "    #     if TRAIN_emb.size(0) == 0:\n",
    "    #         continue\n",
    "    #     # TRAIN_emb, TRAIN_labels = get_model_data_batched(doc_idxs[idx],batched_texts[idx],batched_labels[idx],label_encoder,max_lens_train)\n",
    "    #     loss, acc = train(TRAIN_emb,TRAIN_labels,model,model_opt,loss_function,1)\n",
    "    #     batch_loss.append(loss)\n",
    "    #     batch_acc.append(acc)\n",
    "    #     del TRAIN_emb, TRAIN_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to '../models/BiLSTM.pth'\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"../models/BiLSTM.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 81.25%\n",
      "Test Accuracy 33.81%\n",
      "Test Accuracy 68.00%\n",
      "Test Accuracy 68.52%\n",
      "Test Accuracy 77.32%\n",
      "Test Accuracy 85.96%\n",
      "Test Accuracy 66.18%\n",
      "Test Accuracy 73.45%\n",
      "Test Accuracy 83.92%\n",
      "Test Accuracy 89.21%\n",
      "Test Accuracy 61.84%\n",
      "Test Accuracy 72.12%\n",
      "Test Accuracy 93.30%\n",
      "Test Accuracy 87.41%\n",
      "Test Accuracy 85.94%\n",
      "Test Accuracy 83.87%\n",
      "Test Accuracy 67.35%\n",
      "Test Accuracy 67.57%\n",
      "Test Accuracy 77.42%\n",
      "Test Accuracy 70.00%\n",
      "Test Accuracy 45.65%\n",
      "Test Accuracy 87.88%\n",
      "Test Accuracy 89.61%\n",
      "Test Accuracy 64.15%\n",
      "Test Accuracy 69.64%\n",
      "Test Accuracy 58.06%\n",
      "Test Accuracy 70.37%\n",
      "Test Accuracy 48.84%\n",
      "Test Accuracy 62.71%\n",
      "tensor(72.1155)\n"
     ]
    }
   ],
   "source": [
    "# TEST_emb, TEST_labels = get_model_data(data= TEST_data, encoder= label_encoder,num_of_docs= 5)\n",
    "acc = 0\n",
    "for i in range(29):\n",
    "    TEST_emb = load_tensor(filepath=f\"../test_document/doc_{i}/embedding\")\n",
    "    TEST_labels = load_tensor(filepath=f\"../test_document/doc_{i}/label\")\n",
    "    acc += test_accuracy(TEST_emb, TEST_labels, model)\n",
    "    \n",
    "print(acc/29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 62.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(62.7119)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(TEST_emb, TEST_labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs_plot = [acc[-1].item() for acc in batch_acc]\n",
    "# loss_plot = [np.mean(loss[-5:]) for loss in batch_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accs_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43maccs_plot\u001b[49m)), y\u001b[38;5;241m=\u001b[39m accs_plot)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accs_plot' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x= range(len(accs_plot)), y= accs_plot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x= range(len(batch_loss)), y= batch_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idxs, batched_texts, batched_labels = get_batched_data(TRAIN_data, batch_size= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: torch.Size([91, 1, 768])\tY_train size: torch.Size([91])\n",
      "Tensor saved to '../train_document/doc_0/embedding'\n",
      "Tensor saved to '../train_document/doc_0/label'\n",
      "X_train size: torch.Size([72, 1, 768])\tY_train size: torch.Size([72])\n",
      "Tensor saved to '../train_document/doc_1/embedding'\n",
      "Tensor saved to '../train_document/doc_1/label'\n",
      "X_train size: torch.Size([200, 1, 768])\tY_train size: torch.Size([200])\n",
      "Tensor saved to '../train_document/doc_2/embedding'\n",
      "Tensor saved to '../train_document/doc_2/label'\n",
      "X_train size: torch.Size([119, 1, 768])\tY_train size: torch.Size([119])\n",
      "Tensor saved to '../train_document/doc_3/embedding'\n",
      "Tensor saved to '../train_document/doc_3/label'\n",
      "X_train size: torch.Size([184, 1, 768])\tY_train size: torch.Size([184])\n",
      "Tensor saved to '../train_document/doc_4/embedding'\n",
      "Tensor saved to '../train_document/doc_4/label'\n",
      "X_train size: torch.Size([211, 1, 768])\tY_train size: torch.Size([211])\n",
      "Tensor saved to '../train_document/doc_5/embedding'\n",
      "Tensor saved to '../train_document/doc_5/label'\n",
      "X_train size: torch.Size([140, 1, 768])\tY_train size: torch.Size([140])\n",
      "Tensor saved to '../train_document/doc_6/embedding'\n",
      "Tensor saved to '../train_document/doc_6/label'\n",
      "X_train size: torch.Size([87, 1, 768])\tY_train size: torch.Size([87])\n",
      "Tensor saved to '../train_document/doc_7/embedding'\n",
      "Tensor saved to '../train_document/doc_7/label'\n",
      "X_train size: torch.Size([228, 1, 768])\tY_train size: torch.Size([228])\n",
      "Tensor saved to '../train_document/doc_8/embedding'\n",
      "Tensor saved to '../train_document/doc_8/label'\n",
      "X_train size: torch.Size([99, 1, 768])\tY_train size: torch.Size([99])\n",
      "Tensor saved to '../train_document/doc_9/embedding'\n",
      "Tensor saved to '../train_document/doc_9/label'\n",
      "X_train size: torch.Size([62, 1, 768])\tY_train size: torch.Size([62])\n",
      "Tensor saved to '../train_document/doc_10/embedding'\n",
      "Tensor saved to '../train_document/doc_10/label'\n",
      "X_train size: torch.Size([213, 1, 768])\tY_train size: torch.Size([213])\n",
      "Tensor saved to '../train_document/doc_11/embedding'\n",
      "Tensor saved to '../train_document/doc_11/label'\n",
      "X_train size: torch.Size([111, 1, 768])\tY_train size: torch.Size([111])\n",
      "Tensor saved to '../train_document/doc_12/embedding'\n",
      "Tensor saved to '../train_document/doc_12/label'\n",
      "X_train size: torch.Size([199, 1, 768])\tY_train size: torch.Size([199])\n",
      "Tensor saved to '../train_document/doc_13/embedding'\n",
      "Tensor saved to '../train_document/doc_13/label'\n",
      "X_train size: torch.Size([188, 1, 768])\tY_train size: torch.Size([188])\n",
      "Tensor saved to '../train_document/doc_14/embedding'\n",
      "Tensor saved to '../train_document/doc_14/label'\n",
      "X_train size: torch.Size([271, 1, 768])\tY_train size: torch.Size([271])\n",
      "Tensor saved to '../train_document/doc_15/embedding'\n",
      "Tensor saved to '../train_document/doc_15/label'\n",
      "X_train size: torch.Size([43, 1, 768])\tY_train size: torch.Size([43])\n",
      "Tensor saved to '../train_document/doc_16/embedding'\n",
      "Tensor saved to '../train_document/doc_16/label'\n",
      "X_train size: torch.Size([82, 1, 768])\tY_train size: torch.Size([82])\n",
      "Tensor saved to '../train_document/doc_17/embedding'\n",
      "Tensor saved to '../train_document/doc_17/label'\n",
      "X_train size: torch.Size([171, 1, 768])\tY_train size: torch.Size([171])\n",
      "Tensor saved to '../train_document/doc_18/embedding'\n",
      "Tensor saved to '../train_document/doc_18/label'\n",
      "X_train size: torch.Size([149, 1, 768])\tY_train size: torch.Size([149])\n",
      "Tensor saved to '../train_document/doc_19/embedding'\n",
      "Tensor saved to '../train_document/doc_19/label'\n",
      "X_train size: torch.Size([95, 1, 768])\tY_train size: torch.Size([95])\n",
      "Tensor saved to '../train_document/doc_20/embedding'\n",
      "Tensor saved to '../train_document/doc_20/label'\n",
      "X_train size: torch.Size([56, 1, 768])\tY_train size: torch.Size([56])\n",
      "Tensor saved to '../train_document/doc_21/embedding'\n",
      "Tensor saved to '../train_document/doc_21/label'\n",
      "X_train size: torch.Size([47, 1, 768])\tY_train size: torch.Size([47])\n",
      "Tensor saved to '../train_document/doc_22/embedding'\n",
      "Tensor saved to '../train_document/doc_22/label'\n",
      "X_train size: torch.Size([116, 1, 768])\tY_train size: torch.Size([116])\n",
      "Tensor saved to '../train_document/doc_23/embedding'\n",
      "Tensor saved to '../train_document/doc_23/label'\n",
      "X_train size: torch.Size([111, 1, 768])\tY_train size: torch.Size([111])\n",
      "Tensor saved to '../train_document/doc_24/embedding'\n",
      "Tensor saved to '../train_document/doc_24/label'\n",
      "X_train size: torch.Size([45, 1, 768])\tY_train size: torch.Size([45])\n",
      "Tensor saved to '../train_document/doc_25/embedding'\n",
      "Tensor saved to '../train_document/doc_25/label'\n",
      "X_train size: torch.Size([109, 1, 768])\tY_train size: torch.Size([109])\n",
      "Tensor saved to '../train_document/doc_26/embedding'\n",
      "Tensor saved to '../train_document/doc_26/label'\n",
      "X_train size: torch.Size([155, 1, 768])\tY_train size: torch.Size([155])\n",
      "Tensor saved to '../train_document/doc_27/embedding'\n",
      "Tensor saved to '../train_document/doc_27/label'\n",
      "X_train size: torch.Size([198, 1, 768])\tY_train size: torch.Size([198])\n",
      "Tensor saved to '../train_document/doc_28/embedding'\n",
      "Tensor saved to '../train_document/doc_28/label'\n",
      "X_train size: torch.Size([153, 1, 768])\tY_train size: torch.Size([153])\n",
      "Tensor saved to '../train_document/doc_29/embedding'\n",
      "Tensor saved to '../train_document/doc_29/label'\n",
      "X_train size: torch.Size([50, 1, 768])\tY_train size: torch.Size([50])\n",
      "Tensor saved to '../train_document/doc_30/embedding'\n",
      "Tensor saved to '../train_document/doc_30/label'\n",
      "X_train size: torch.Size([44, 1, 768])\tY_train size: torch.Size([44])\n",
      "Tensor saved to '../train_document/doc_31/embedding'\n",
      "Tensor saved to '../train_document/doc_31/label'\n",
      "X_train size: torch.Size([264, 1, 768])\tY_train size: torch.Size([264])\n",
      "Tensor saved to '../train_document/doc_32/embedding'\n",
      "Tensor saved to '../train_document/doc_32/label'\n",
      "X_train size: torch.Size([114, 1, 768])\tY_train size: torch.Size([114])\n",
      "Tensor saved to '../train_document/doc_33/embedding'\n",
      "Tensor saved to '../train_document/doc_33/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../train_document/doc_34/embedding'\n",
      "Tensor saved to '../train_document/doc_34/label'\n",
      "X_train size: torch.Size([243, 1, 768])\tY_train size: torch.Size([243])\n",
      "Tensor saved to '../train_document/doc_35/embedding'\n",
      "Tensor saved to '../train_document/doc_35/label'\n",
      "X_train size: torch.Size([107, 1, 768])\tY_train size: torch.Size([107])\n",
      "Tensor saved to '../train_document/doc_36/embedding'\n",
      "Tensor saved to '../train_document/doc_36/label'\n",
      "X_train size: torch.Size([127, 1, 768])\tY_train size: torch.Size([127])\n",
      "Tensor saved to '../train_document/doc_37/embedding'\n",
      "Tensor saved to '../train_document/doc_37/label'\n",
      "X_train size: torch.Size([188, 1, 768])\tY_train size: torch.Size([188])\n",
      "Tensor saved to '../train_document/doc_38/embedding'\n",
      "Tensor saved to '../train_document/doc_38/label'\n",
      "X_train size: torch.Size([189, 1, 768])\tY_train size: torch.Size([189])\n",
      "Tensor saved to '../train_document/doc_39/embedding'\n",
      "Tensor saved to '../train_document/doc_39/label'\n",
      "X_train size: torch.Size([157, 1, 768])\tY_train size: torch.Size([157])\n",
      "Tensor saved to '../train_document/doc_40/embedding'\n",
      "Tensor saved to '../train_document/doc_40/label'\n",
      "X_train size: torch.Size([62, 1, 768])\tY_train size: torch.Size([62])\n",
      "Tensor saved to '../train_document/doc_41/embedding'\n",
      "Tensor saved to '../train_document/doc_41/label'\n",
      "X_train size: torch.Size([120, 1, 768])\tY_train size: torch.Size([120])\n",
      "Tensor saved to '../train_document/doc_42/embedding'\n",
      "Tensor saved to '../train_document/doc_42/label'\n",
      "X_train size: torch.Size([142, 1, 768])\tY_train size: torch.Size([142])\n",
      "Tensor saved to '../train_document/doc_43/embedding'\n",
      "Tensor saved to '../train_document/doc_43/label'\n",
      "X_train size: torch.Size([75, 1, 768])\tY_train size: torch.Size([75])\n",
      "Tensor saved to '../train_document/doc_44/embedding'\n",
      "Tensor saved to '../train_document/doc_44/label'\n",
      "X_train size: torch.Size([146, 1, 768])\tY_train size: torch.Size([146])\n",
      "Tensor saved to '../train_document/doc_45/embedding'\n",
      "Tensor saved to '../train_document/doc_45/label'\n",
      "X_train size: torch.Size([185, 1, 768])\tY_train size: torch.Size([185])\n",
      "Tensor saved to '../train_document/doc_46/embedding'\n",
      "Tensor saved to '../train_document/doc_46/label'\n",
      "X_train size: torch.Size([53, 1, 768])\tY_train size: torch.Size([53])\n",
      "Tensor saved to '../train_document/doc_47/embedding'\n",
      "Tensor saved to '../train_document/doc_47/label'\n",
      "X_train size: torch.Size([73, 1, 768])\tY_train size: torch.Size([73])\n",
      "Tensor saved to '../train_document/doc_48/embedding'\n",
      "Tensor saved to '../train_document/doc_48/label'\n",
      "X_train size: torch.Size([79, 1, 768])\tY_train size: torch.Size([79])\n",
      "Tensor saved to '../train_document/doc_49/embedding'\n",
      "Tensor saved to '../train_document/doc_49/label'\n",
      "X_train size: torch.Size([187, 1, 768])\tY_train size: torch.Size([187])\n",
      "Tensor saved to '../train_document/doc_50/embedding'\n",
      "Tensor saved to '../train_document/doc_50/label'\n",
      "X_train size: torch.Size([82, 1, 768])\tY_train size: torch.Size([82])\n",
      "Tensor saved to '../train_document/doc_51/embedding'\n",
      "Tensor saved to '../train_document/doc_51/label'\n",
      "X_train size: torch.Size([88, 1, 768])\tY_train size: torch.Size([88])\n",
      "Tensor saved to '../train_document/doc_52/embedding'\n",
      "Tensor saved to '../train_document/doc_52/label'\n",
      "X_train size: torch.Size([59, 1, 768])\tY_train size: torch.Size([59])\n",
      "Tensor saved to '../train_document/doc_53/embedding'\n",
      "Tensor saved to '../train_document/doc_53/label'\n",
      "X_train size: torch.Size([59, 1, 768])\tY_train size: torch.Size([59])\n",
      "Tensor saved to '../train_document/doc_54/embedding'\n",
      "Tensor saved to '../train_document/doc_54/label'\n",
      "X_train size: torch.Size([110, 1, 768])\tY_train size: torch.Size([110])\n",
      "Tensor saved to '../train_document/doc_55/embedding'\n",
      "Tensor saved to '../train_document/doc_55/label'\n",
      "X_train size: torch.Size([141, 1, 768])\tY_train size: torch.Size([141])\n",
      "Tensor saved to '../train_document/doc_56/embedding'\n",
      "Tensor saved to '../train_document/doc_56/label'\n",
      "X_train size: torch.Size([31, 1, 768])\tY_train size: torch.Size([31])\n",
      "Tensor saved to '../train_document/doc_57/embedding'\n",
      "Tensor saved to '../train_document/doc_57/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../train_document/doc_58/embedding'\n",
      "Tensor saved to '../train_document/doc_58/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../train_document/doc_59/embedding'\n",
      "Tensor saved to '../train_document/doc_59/label'\n",
      "X_train size: torch.Size([31, 1, 768])\tY_train size: torch.Size([31])\n",
      "Tensor saved to '../train_document/doc_60/embedding'\n",
      "Tensor saved to '../train_document/doc_60/label'\n",
      "X_train size: torch.Size([39, 1, 768])\tY_train size: torch.Size([39])\n",
      "Tensor saved to '../train_document/doc_61/embedding'\n",
      "Tensor saved to '../train_document/doc_61/label'\n",
      "X_train size: torch.Size([208, 1, 768])\tY_train size: torch.Size([208])\n",
      "Tensor saved to '../train_document/doc_62/embedding'\n",
      "Tensor saved to '../train_document/doc_62/label'\n",
      "X_train size: torch.Size([115, 1, 768])\tY_train size: torch.Size([115])\n",
      "Tensor saved to '../train_document/doc_63/embedding'\n",
      "Tensor saved to '../train_document/doc_63/label'\n",
      "X_train size: torch.Size([155, 1, 768])\tY_train size: torch.Size([155])\n",
      "Tensor saved to '../train_document/doc_64/embedding'\n",
      "Tensor saved to '../train_document/doc_64/label'\n",
      "X_train size: torch.Size([123, 1, 768])\tY_train size: torch.Size([123])\n",
      "Tensor saved to '../train_document/doc_65/embedding'\n",
      "Tensor saved to '../train_document/doc_65/label'\n",
      "X_train size: torch.Size([52, 1, 768])\tY_train size: torch.Size([52])\n",
      "Tensor saved to '../train_document/doc_66/embedding'\n",
      "Tensor saved to '../train_document/doc_66/label'\n",
      "X_train size: torch.Size([143, 1, 768])\tY_train size: torch.Size([143])\n",
      "Tensor saved to '../train_document/doc_67/embedding'\n",
      "Tensor saved to '../train_document/doc_67/label'\n",
      "X_train size: torch.Size([142, 1, 768])\tY_train size: torch.Size([142])\n",
      "Tensor saved to '../train_document/doc_68/embedding'\n",
      "Tensor saved to '../train_document/doc_68/label'\n",
      "X_train size: torch.Size([0, 1, 768])\tY_train size: torch.Size([0])\n",
      "Tensor saved to '../train_document/doc_69/embedding'\n",
      "Tensor saved to '../train_document/doc_69/label'\n",
      "X_train size: torch.Size([77, 1, 768])\tY_train size: torch.Size([77])\n",
      "Tensor saved to '../train_document/doc_70/embedding'\n",
      "Tensor saved to '../train_document/doc_70/label'\n",
      "X_train size: torch.Size([116, 1, 768])\tY_train size: torch.Size([116])\n",
      "Tensor saved to '../train_document/doc_71/embedding'\n",
      "Tensor saved to '../train_document/doc_71/label'\n",
      "X_train size: torch.Size([87, 1, 768])\tY_train size: torch.Size([87])\n",
      "Tensor saved to '../train_document/doc_72/embedding'\n",
      "Tensor saved to '../train_document/doc_72/label'\n",
      "X_train size: torch.Size([122, 1, 768])\tY_train size: torch.Size([122])\n",
      "Tensor saved to '../train_document/doc_73/embedding'\n",
      "Tensor saved to '../train_document/doc_73/label'\n",
      "X_train size: torch.Size([111, 1, 768])\tY_train size: torch.Size([111])\n",
      "Tensor saved to '../train_document/doc_74/embedding'\n",
      "Tensor saved to '../train_document/doc_74/label'\n",
      "X_train size: torch.Size([95, 1, 768])\tY_train size: torch.Size([95])\n",
      "Tensor saved to '../train_document/doc_75/embedding'\n",
      "Tensor saved to '../train_document/doc_75/label'\n",
      "X_train size: torch.Size([184, 1, 768])\tY_train size: torch.Size([184])\n",
      "Tensor saved to '../train_document/doc_76/embedding'\n",
      "Tensor saved to '../train_document/doc_76/label'\n",
      "X_train size: torch.Size([144, 1, 768])\tY_train size: torch.Size([144])\n",
      "Tensor saved to '../train_document/doc_77/embedding'\n",
      "Tensor saved to '../train_document/doc_77/label'\n",
      "X_train size: torch.Size([35, 1, 768])\tY_train size: torch.Size([35])\n",
      "Tensor saved to '../train_document/doc_78/embedding'\n",
      "Tensor saved to '../train_document/doc_78/label'\n",
      "X_train size: torch.Size([140, 1, 768])\tY_train size: torch.Size([140])\n",
      "Tensor saved to '../train_document/doc_79/embedding'\n",
      "Tensor saved to '../train_document/doc_79/label'\n",
      "X_train size: torch.Size([73, 1, 768])\tY_train size: torch.Size([73])\n",
      "Tensor saved to '../train_document/doc_80/embedding'\n",
      "Tensor saved to '../train_document/doc_80/label'\n",
      "X_train size: torch.Size([137, 1, 768])\tY_train size: torch.Size([137])\n",
      "Tensor saved to '../train_document/doc_81/embedding'\n",
      "Tensor saved to '../train_document/doc_81/label'\n",
      "X_train size: torch.Size([24, 1, 768])\tY_train size: torch.Size([24])\n",
      "Tensor saved to '../train_document/doc_82/embedding'\n",
      "Tensor saved to '../train_document/doc_82/label'\n",
      "X_train size: torch.Size([113, 1, 768])\tY_train size: torch.Size([113])\n",
      "Tensor saved to '../train_document/doc_83/embedding'\n",
      "Tensor saved to '../train_document/doc_83/label'\n",
      "X_train size: torch.Size([105, 1, 768])\tY_train size: torch.Size([105])\n",
      "Tensor saved to '../train_document/doc_84/embedding'\n",
      "Tensor saved to '../train_document/doc_84/label'\n",
      "X_train size: torch.Size([80, 1, 768])\tY_train size: torch.Size([80])\n",
      "Tensor saved to '../train_document/doc_85/embedding'\n",
      "Tensor saved to '../train_document/doc_85/label'\n",
      "X_train size: torch.Size([106, 1, 768])\tY_train size: torch.Size([106])\n",
      "Tensor saved to '../train_document/doc_86/embedding'\n",
      "Tensor saved to '../train_document/doc_86/label'\n",
      "X_train size: torch.Size([44, 1, 768])\tY_train size: torch.Size([44])\n",
      "Tensor saved to '../train_document/doc_87/embedding'\n",
      "Tensor saved to '../train_document/doc_87/label'\n",
      "X_train size: torch.Size([105, 1, 768])\tY_train size: torch.Size([105])\n",
      "Tensor saved to '../train_document/doc_88/embedding'\n",
      "Tensor saved to '../train_document/doc_88/label'\n",
      "X_train size: torch.Size([53, 1, 768])\tY_train size: torch.Size([53])\n",
      "Tensor saved to '../train_document/doc_89/embedding'\n",
      "Tensor saved to '../train_document/doc_89/label'\n",
      "X_train size: torch.Size([136, 1, 768])\tY_train size: torch.Size([136])\n",
      "Tensor saved to '../train_document/doc_90/embedding'\n",
      "Tensor saved to '../train_document/doc_90/label'\n",
      "X_train size: torch.Size([83, 1, 768])\tY_train size: torch.Size([83])\n",
      "Tensor saved to '../train_document/doc_91/embedding'\n",
      "Tensor saved to '../train_document/doc_91/label'\n",
      "X_train size: torch.Size([221, 1, 768])\tY_train size: torch.Size([221])\n",
      "Tensor saved to '../train_document/doc_92/embedding'\n",
      "Tensor saved to '../train_document/doc_92/label'\n",
      "X_train size: torch.Size([150, 1, 768])\tY_train size: torch.Size([150])\n",
      "Tensor saved to '../train_document/doc_93/embedding'\n",
      "Tensor saved to '../train_document/doc_93/label'\n",
      "X_train size: torch.Size([114, 1, 768])\tY_train size: torch.Size([114])\n",
      "Tensor saved to '../train_document/doc_94/embedding'\n",
      "Tensor saved to '../train_document/doc_94/label'\n",
      "X_train size: torch.Size([57, 1, 768])\tY_train size: torch.Size([57])\n",
      "Tensor saved to '../train_document/doc_95/embedding'\n",
      "Tensor saved to '../train_document/doc_95/label'\n",
      "X_train size: torch.Size([57, 1, 768])\tY_train size: torch.Size([57])\n",
      "Tensor saved to '../train_document/doc_96/embedding'\n",
      "Tensor saved to '../train_document/doc_96/label'\n",
      "X_train size: torch.Size([70, 1, 768])\tY_train size: torch.Size([70])\n",
      "Tensor saved to '../train_document/doc_97/embedding'\n",
      "Tensor saved to '../train_document/doc_97/label'\n",
      "X_train size: torch.Size([264, 1, 768])\tY_train size: torch.Size([264])\n",
      "Tensor saved to '../train_document/doc_98/embedding'\n",
      "Tensor saved to '../train_document/doc_98/label'\n",
      "X_train size: torch.Size([167, 1, 768])\tY_train size: torch.Size([167])\n",
      "Tensor saved to '../train_document/doc_99/embedding'\n",
      "Tensor saved to '../train_document/doc_99/label'\n",
      "X_train size: torch.Size([49, 1, 768])\tY_train size: torch.Size([49])\n",
      "Tensor saved to '../train_document/doc_100/embedding'\n",
      "Tensor saved to '../train_document/doc_100/label'\n",
      "X_train size: torch.Size([63, 1, 768])\tY_train size: torch.Size([63])\n",
      "Tensor saved to '../train_document/doc_101/embedding'\n",
      "Tensor saved to '../train_document/doc_101/label'\n",
      "X_train size: torch.Size([74, 1, 768])\tY_train size: torch.Size([74])\n",
      "Tensor saved to '../train_document/doc_102/embedding'\n",
      "Tensor saved to '../train_document/doc_102/label'\n",
      "X_train size: torch.Size([123, 1, 768])\tY_train size: torch.Size([123])\n",
      "Tensor saved to '../train_document/doc_103/embedding'\n",
      "Tensor saved to '../train_document/doc_103/label'\n",
      "X_train size: torch.Size([147, 1, 768])\tY_train size: torch.Size([147])\n",
      "Tensor saved to '../train_document/doc_104/embedding'\n",
      "Tensor saved to '../train_document/doc_104/label'\n",
      "X_train size: torch.Size([180, 1, 768])\tY_train size: torch.Size([180])\n",
      "Tensor saved to '../train_document/doc_105/embedding'\n",
      "Tensor saved to '../train_document/doc_105/label'\n",
      "X_train size: torch.Size([71, 1, 768])\tY_train size: torch.Size([71])\n",
      "Tensor saved to '../train_document/doc_106/embedding'\n",
      "Tensor saved to '../train_document/doc_106/label'\n",
      "X_train size: torch.Size([174, 1, 768])\tY_train size: torch.Size([174])\n",
      "Tensor saved to '../train_document/doc_107/embedding'\n",
      "Tensor saved to '../train_document/doc_107/label'\n",
      "X_train size: torch.Size([126, 1, 768])\tY_train size: torch.Size([126])\n",
      "Tensor saved to '../train_document/doc_108/embedding'\n",
      "Tensor saved to '../train_document/doc_108/label'\n",
      "X_train size: torch.Size([129, 1, 768])\tY_train size: torch.Size([129])\n",
      "Tensor saved to '../train_document/doc_109/embedding'\n",
      "Tensor saved to '../train_document/doc_109/label'\n",
      "X_train size: torch.Size([32, 1, 768])\tY_train size: torch.Size([32])\n",
      "Tensor saved to '../train_document/doc_110/embedding'\n",
      "Tensor saved to '../train_document/doc_110/label'\n",
      "X_train size: torch.Size([121, 1, 768])\tY_train size: torch.Size([121])\n",
      "Tensor saved to '../train_document/doc_111/embedding'\n",
      "Tensor saved to '../train_document/doc_111/label'\n",
      "X_train size: torch.Size([60, 1, 768])\tY_train size: torch.Size([60])\n",
      "Tensor saved to '../train_document/doc_112/embedding'\n",
      "Tensor saved to '../train_document/doc_112/label'\n",
      "X_train size: torch.Size([94, 1, 768])\tY_train size: torch.Size([94])\n",
      "Tensor saved to '../train_document/doc_113/embedding'\n",
      "Tensor saved to '../train_document/doc_113/label'\n",
      "X_train size: torch.Size([121, 1, 768])\tY_train size: torch.Size([121])\n",
      "Tensor saved to '../train_document/doc_114/embedding'\n",
      "Tensor saved to '../train_document/doc_114/label'\n",
      "X_train size: torch.Size([115, 1, 768])\tY_train size: torch.Size([115])\n",
      "Tensor saved to '../train_document/doc_115/embedding'\n",
      "Tensor saved to '../train_document/doc_115/label'\n",
      "X_train size: torch.Size([153, 1, 768])\tY_train size: torch.Size([153])\n",
      "Tensor saved to '../train_document/doc_116/embedding'\n",
      "Tensor saved to '../train_document/doc_116/label'\n",
      "X_train size: torch.Size([308, 1, 768])\tY_train size: torch.Size([308])\n",
      "Tensor saved to '../train_document/doc_117/embedding'\n",
      "Tensor saved to '../train_document/doc_117/label'\n",
      "X_train size: torch.Size([44, 1, 768])\tY_train size: torch.Size([44])\n",
      "Tensor saved to '../train_document/doc_118/embedding'\n",
      "Tensor saved to '../train_document/doc_118/label'\n",
      "X_train size: torch.Size([139, 1, 768])\tY_train size: torch.Size([139])\n",
      "Tensor saved to '../train_document/doc_119/embedding'\n",
      "Tensor saved to '../train_document/doc_119/label'\n",
      "X_train size: torch.Size([71, 1, 768])\tY_train size: torch.Size([71])\n",
      "Tensor saved to '../train_document/doc_120/embedding'\n",
      "Tensor saved to '../train_document/doc_120/label'\n",
      "X_train size: torch.Size([63, 1, 768])\tY_train size: torch.Size([63])\n",
      "Tensor saved to '../train_document/doc_121/embedding'\n",
      "Tensor saved to '../train_document/doc_121/label'\n",
      "X_train size: torch.Size([201, 1, 768])\tY_train size: torch.Size([201])\n",
      "Tensor saved to '../train_document/doc_122/embedding'\n",
      "Tensor saved to '../train_document/doc_122/label'\n",
      "X_train size: torch.Size([31, 1, 768])\tY_train size: torch.Size([31])\n",
      "Tensor saved to '../train_document/doc_123/embedding'\n",
      "Tensor saved to '../train_document/doc_123/label'\n",
      "X_train size: torch.Size([168, 1, 768])\tY_train size: torch.Size([168])\n",
      "Tensor saved to '../train_document/doc_124/embedding'\n",
      "Tensor saved to '../train_document/doc_124/label'\n",
      "X_train size: torch.Size([213, 1, 768])\tY_train size: torch.Size([213])\n",
      "Tensor saved to '../train_document/doc_125/embedding'\n",
      "Tensor saved to '../train_document/doc_125/label'\n",
      "X_train size: torch.Size([96, 1, 768])\tY_train size: torch.Size([96])\n",
      "Tensor saved to '../train_document/doc_126/embedding'\n",
      "Tensor saved to '../train_document/doc_126/label'\n",
      "X_train size: torch.Size([85, 1, 768])\tY_train size: torch.Size([85])\n",
      "Tensor saved to '../train_document/doc_127/embedding'\n",
      "Tensor saved to '../train_document/doc_127/label'\n",
      "X_train size: torch.Size([174, 1, 768])\tY_train size: torch.Size([174])\n",
      "Tensor saved to '../train_document/doc_128/embedding'\n",
      "Tensor saved to '../train_document/doc_128/label'\n",
      "X_train size: torch.Size([53, 1, 768])\tY_train size: torch.Size([53])\n",
      "Tensor saved to '../train_document/doc_129/embedding'\n",
      "Tensor saved to '../train_document/doc_129/label'\n",
      "X_train size: torch.Size([111, 1, 768])\tY_train size: torch.Size([111])\n",
      "Tensor saved to '../train_document/doc_130/embedding'\n",
      "Tensor saved to '../train_document/doc_130/label'\n",
      "X_train size: torch.Size([130, 1, 768])\tY_train size: torch.Size([130])\n",
      "Tensor saved to '../train_document/doc_131/embedding'\n",
      "Tensor saved to '../train_document/doc_131/label'\n",
      "X_train size: torch.Size([126, 1, 768])\tY_train size: torch.Size([126])\n",
      "Tensor saved to '../train_document/doc_132/embedding'\n",
      "Tensor saved to '../train_document/doc_132/label'\n",
      "X_train size: torch.Size([158, 1, 768])\tY_train size: torch.Size([158])\n",
      "Tensor saved to '../train_document/doc_133/embedding'\n",
      "Tensor saved to '../train_document/doc_133/label'\n",
      "X_train size: torch.Size([103, 1, 768])\tY_train size: torch.Size([103])\n",
      "Tensor saved to '../train_document/doc_134/embedding'\n",
      "Tensor saved to '../train_document/doc_134/label'\n",
      "X_train size: torch.Size([130, 1, 768])\tY_train size: torch.Size([130])\n",
      "Tensor saved to '../train_document/doc_135/embedding'\n",
      "Tensor saved to '../train_document/doc_135/label'\n",
      "X_train size: torch.Size([65, 1, 768])\tY_train size: torch.Size([65])\n",
      "Tensor saved to '../train_document/doc_136/embedding'\n",
      "Tensor saved to '../train_document/doc_136/label'\n",
      "X_train size: torch.Size([98, 1, 768])\tY_train size: torch.Size([98])\n",
      "Tensor saved to '../train_document/doc_137/embedding'\n",
      "Tensor saved to '../train_document/doc_137/label'\n",
      "X_train size: torch.Size([161, 1, 768])\tY_train size: torch.Size([161])\n",
      "Tensor saved to '../train_document/doc_138/embedding'\n",
      "Tensor saved to '../train_document/doc_138/label'\n",
      "X_train size: torch.Size([93, 1, 768])\tY_train size: torch.Size([93])\n",
      "Tensor saved to '../train_document/doc_139/embedding'\n",
      "Tensor saved to '../train_document/doc_139/label'\n",
      "X_train size: torch.Size([67, 1, 768])\tY_train size: torch.Size([67])\n",
      "Tensor saved to '../train_document/doc_140/embedding'\n",
      "Tensor saved to '../train_document/doc_140/label'\n",
      "X_train size: torch.Size([173, 1, 768])\tY_train size: torch.Size([173])\n",
      "Tensor saved to '../train_document/doc_141/embedding'\n",
      "Tensor saved to '../train_document/doc_141/label'\n",
      "X_train size: torch.Size([234, 1, 768])\tY_train size: torch.Size([234])\n",
      "Tensor saved to '../train_document/doc_142/embedding'\n",
      "Tensor saved to '../train_document/doc_142/label'\n",
      "X_train size: torch.Size([153, 1, 768])\tY_train size: torch.Size([153])\n",
      "Tensor saved to '../train_document/doc_143/embedding'\n",
      "Tensor saved to '../train_document/doc_143/label'\n",
      "X_train size: torch.Size([103, 1, 768])\tY_train size: torch.Size([103])\n",
      "Tensor saved to '../train_document/doc_144/embedding'\n",
      "Tensor saved to '../train_document/doc_144/label'\n",
      "X_train size: torch.Size([42, 1, 768])\tY_train size: torch.Size([42])\n",
      "Tensor saved to '../train_document/doc_145/embedding'\n",
      "Tensor saved to '../train_document/doc_145/label'\n",
      "X_train size: torch.Size([164, 1, 768])\tY_train size: torch.Size([164])\n",
      "Tensor saved to '../train_document/doc_146/embedding'\n",
      "Tensor saved to '../train_document/doc_146/label'\n",
      "X_train size: torch.Size([36, 1, 768])\tY_train size: torch.Size([36])\n",
      "Tensor saved to '../train_document/doc_147/embedding'\n",
      "Tensor saved to '../train_document/doc_147/label'\n",
      "X_train size: torch.Size([66, 1, 768])\tY_train size: torch.Size([66])\n",
      "Tensor saved to '../train_document/doc_148/embedding'\n",
      "Tensor saved to '../train_document/doc_148/label'\n",
      "X_train size: torch.Size([386, 1, 768])\tY_train size: torch.Size([386])\n",
      "Tensor saved to '../train_document/doc_149/embedding'\n",
      "Tensor saved to '../train_document/doc_149/label'\n",
      "X_train size: torch.Size([119, 1, 768])\tY_train size: torch.Size([119])\n",
      "Tensor saved to '../train_document/doc_150/embedding'\n",
      "Tensor saved to '../train_document/doc_150/label'\n",
      "X_train size: torch.Size([83, 1, 768])\tY_train size: torch.Size([83])\n",
      "Tensor saved to '../train_document/doc_151/embedding'\n",
      "Tensor saved to '../train_document/doc_151/label'\n",
      "X_train size: torch.Size([200, 1, 768])\tY_train size: torch.Size([200])\n",
      "Tensor saved to '../train_document/doc_152/embedding'\n",
      "Tensor saved to '../train_document/doc_152/label'\n",
      "X_train size: torch.Size([159, 1, 768])\tY_train size: torch.Size([159])\n",
      "Tensor saved to '../train_document/doc_153/embedding'\n",
      "Tensor saved to '../train_document/doc_153/label'\n",
      "X_train size: torch.Size([75, 1, 768])\tY_train size: torch.Size([75])\n",
      "Tensor saved to '../train_document/doc_154/embedding'\n",
      "Tensor saved to '../train_document/doc_154/label'\n",
      "X_train size: torch.Size([75, 1, 768])\tY_train size: torch.Size([75])\n",
      "Tensor saved to '../train_document/doc_155/embedding'\n",
      "Tensor saved to '../train_document/doc_155/label'\n",
      "X_train size: torch.Size([63, 1, 768])\tY_train size: torch.Size([63])\n",
      "Tensor saved to '../train_document/doc_156/embedding'\n",
      "Tensor saved to '../train_document/doc_156/label'\n",
      "X_train size: torch.Size([65, 1, 768])\tY_train size: torch.Size([65])\n",
      "Tensor saved to '../train_document/doc_157/embedding'\n",
      "Tensor saved to '../train_document/doc_157/label'\n",
      "X_train size: torch.Size([97, 1, 768])\tY_train size: torch.Size([97])\n",
      "Tensor saved to '../train_document/doc_158/embedding'\n",
      "Tensor saved to '../train_document/doc_158/label'\n",
      "X_train size: torch.Size([75, 1, 768])\tY_train size: torch.Size([75])\n",
      "Tensor saved to '../train_document/doc_159/embedding'\n",
      "Tensor saved to '../train_document/doc_159/label'\n",
      "X_train size: torch.Size([104, 1, 768])\tY_train size: torch.Size([104])\n",
      "Tensor saved to '../train_document/doc_160/embedding'\n",
      "Tensor saved to '../train_document/doc_160/label'\n",
      "X_train size: torch.Size([44, 1, 768])\tY_train size: torch.Size([44])\n",
      "Tensor saved to '../train_document/doc_161/embedding'\n",
      "Tensor saved to '../train_document/doc_161/label'\n",
      "X_train size: torch.Size([63, 1, 768])\tY_train size: torch.Size([63])\n",
      "Tensor saved to '../train_document/doc_162/embedding'\n",
      "Tensor saved to '../train_document/doc_162/label'\n",
      "X_train size: torch.Size([79, 1, 768])\tY_train size: torch.Size([79])\n",
      "Tensor saved to '../train_document/doc_163/embedding'\n",
      "Tensor saved to '../train_document/doc_163/label'\n",
      "X_train size: torch.Size([190, 1, 768])\tY_train size: torch.Size([190])\n",
      "Tensor saved to '../train_document/doc_164/embedding'\n",
      "Tensor saved to '../train_document/doc_164/label'\n",
      "X_train size: torch.Size([33, 1, 768])\tY_train size: torch.Size([33])\n",
      "Tensor saved to '../train_document/doc_165/embedding'\n",
      "Tensor saved to '../train_document/doc_165/label'\n",
      "X_train size: torch.Size([91, 1, 768])\tY_train size: torch.Size([91])\n",
      "Tensor saved to '../train_document/doc_166/embedding'\n",
      "Tensor saved to '../train_document/doc_166/label'\n",
      "X_train size: torch.Size([96, 1, 768])\tY_train size: torch.Size([96])\n",
      "Tensor saved to '../train_document/doc_167/embedding'\n",
      "Tensor saved to '../train_document/doc_167/label'\n",
      "X_train size: torch.Size([52, 1, 768])\tY_train size: torch.Size([52])\n",
      "Tensor saved to '../train_document/doc_168/embedding'\n",
      "Tensor saved to '../train_document/doc_168/label'\n",
      "X_train size: torch.Size([91, 1, 768])\tY_train size: torch.Size([91])\n",
      "Tensor saved to '../train_document/doc_169/embedding'\n",
      "Tensor saved to '../train_document/doc_169/label'\n",
      "X_train size: torch.Size([251, 1, 768])\tY_train size: torch.Size([251])\n",
      "Tensor saved to '../train_document/doc_170/embedding'\n",
      "Tensor saved to '../train_document/doc_170/label'\n",
      "X_train size: torch.Size([117, 1, 768])\tY_train size: torch.Size([117])\n",
      "Tensor saved to '../train_document/doc_171/embedding'\n",
      "Tensor saved to '../train_document/doc_171/label'\n",
      "X_train size: torch.Size([146, 1, 768])\tY_train size: torch.Size([146])\n",
      "Tensor saved to '../train_document/doc_172/embedding'\n",
      "Tensor saved to '../train_document/doc_172/label'\n",
      "X_train size: torch.Size([84, 1, 768])\tY_train size: torch.Size([84])\n",
      "Tensor saved to '../train_document/doc_173/embedding'\n",
      "Tensor saved to '../train_document/doc_173/label'\n",
      "X_train size: torch.Size([223, 1, 768])\tY_train size: torch.Size([223])\n",
      "Tensor saved to '../train_document/doc_174/embedding'\n",
      "Tensor saved to '../train_document/doc_174/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../train_document/doc_175/embedding'\n",
      "Tensor saved to '../train_document/doc_175/label'\n",
      "X_train size: torch.Size([248, 1, 768])\tY_train size: torch.Size([248])\n",
      "Tensor saved to '../train_document/doc_176/embedding'\n",
      "Tensor saved to '../train_document/doc_176/label'\n",
      "X_train size: torch.Size([69, 1, 768])\tY_train size: torch.Size([69])\n",
      "Tensor saved to '../train_document/doc_177/embedding'\n",
      "Tensor saved to '../train_document/doc_177/label'\n",
      "X_train size: torch.Size([89, 1, 768])\tY_train size: torch.Size([89])\n",
      "Tensor saved to '../train_document/doc_178/embedding'\n",
      "Tensor saved to '../train_document/doc_178/label'\n",
      "X_train size: torch.Size([124, 1, 768])\tY_train size: torch.Size([124])\n",
      "Tensor saved to '../train_document/doc_179/embedding'\n",
      "Tensor saved to '../train_document/doc_179/label'\n",
      "X_train size: torch.Size([45, 1, 768])\tY_train size: torch.Size([45])\n",
      "Tensor saved to '../train_document/doc_180/embedding'\n",
      "Tensor saved to '../train_document/doc_180/label'\n",
      "X_train size: torch.Size([95, 1, 768])\tY_train size: torch.Size([95])\n",
      "Tensor saved to '../train_document/doc_181/embedding'\n",
      "Tensor saved to '../train_document/doc_181/label'\n",
      "X_train size: torch.Size([131, 1, 768])\tY_train size: torch.Size([131])\n",
      "Tensor saved to '../train_document/doc_182/embedding'\n",
      "Tensor saved to '../train_document/doc_182/label'\n",
      "X_train size: torch.Size([117, 1, 768])\tY_train size: torch.Size([117])\n",
      "Tensor saved to '../train_document/doc_183/embedding'\n",
      "Tensor saved to '../train_document/doc_183/label'\n",
      "X_train size: torch.Size([27, 1, 768])\tY_train size: torch.Size([27])\n",
      "Tensor saved to '../train_document/doc_184/embedding'\n",
      "Tensor saved to '../train_document/doc_184/label'\n",
      "X_train size: torch.Size([106, 1, 768])\tY_train size: torch.Size([106])\n",
      "Tensor saved to '../train_document/doc_185/embedding'\n",
      "Tensor saved to '../train_document/doc_185/label'\n",
      "X_train size: torch.Size([244, 1, 768])\tY_train size: torch.Size([244])\n",
      "Tensor saved to '../train_document/doc_186/embedding'\n",
      "Tensor saved to '../train_document/doc_186/label'\n",
      "X_train size: torch.Size([87, 1, 768])\tY_train size: torch.Size([87])\n",
      "Tensor saved to '../train_document/doc_187/embedding'\n",
      "Tensor saved to '../train_document/doc_187/label'\n",
      "X_train size: torch.Size([78, 1, 768])\tY_train size: torch.Size([78])\n",
      "Tensor saved to '../train_document/doc_188/embedding'\n",
      "Tensor saved to '../train_document/doc_188/label'\n",
      "X_train size: torch.Size([97, 1, 768])\tY_train size: torch.Size([97])\n",
      "Tensor saved to '../train_document/doc_189/embedding'\n",
      "Tensor saved to '../train_document/doc_189/label'\n",
      "X_train size: torch.Size([36, 1, 768])\tY_train size: torch.Size([36])\n",
      "Tensor saved to '../train_document/doc_190/embedding'\n",
      "Tensor saved to '../train_document/doc_190/label'\n",
      "X_train size: torch.Size([128, 1, 768])\tY_train size: torch.Size([128])\n",
      "Tensor saved to '../train_document/doc_191/embedding'\n",
      "Tensor saved to '../train_document/doc_191/label'\n",
      "X_train size: torch.Size([154, 1, 768])\tY_train size: torch.Size([154])\n",
      "Tensor saved to '../train_document/doc_192/embedding'\n",
      "Tensor saved to '../train_document/doc_192/label'\n",
      "X_train size: torch.Size([115, 1, 768])\tY_train size: torch.Size([115])\n",
      "Tensor saved to '../train_document/doc_193/embedding'\n",
      "Tensor saved to '../train_document/doc_193/label'\n",
      "X_train size: torch.Size([61, 1, 768])\tY_train size: torch.Size([61])\n",
      "Tensor saved to '../train_document/doc_194/embedding'\n",
      "Tensor saved to '../train_document/doc_194/label'\n",
      "X_train size: torch.Size([245, 1, 768])\tY_train size: torch.Size([245])\n",
      "Tensor saved to '../train_document/doc_195/embedding'\n",
      "Tensor saved to '../train_document/doc_195/label'\n",
      "X_train size: torch.Size([104, 1, 768])\tY_train size: torch.Size([104])\n",
      "Tensor saved to '../train_document/doc_196/embedding'\n",
      "Tensor saved to '../train_document/doc_196/label'\n",
      "X_train size: torch.Size([91, 1, 768])\tY_train size: torch.Size([91])\n",
      "Tensor saved to '../train_document/doc_197/embedding'\n",
      "Tensor saved to '../train_document/doc_197/label'\n",
      "X_train size: torch.Size([120, 1, 768])\tY_train size: torch.Size([120])\n",
      "Tensor saved to '../train_document/doc_198/embedding'\n",
      "Tensor saved to '../train_document/doc_198/label'\n",
      "X_train size: torch.Size([89, 1, 768])\tY_train size: torch.Size([89])\n",
      "Tensor saved to '../train_document/doc_199/embedding'\n",
      "Tensor saved to '../train_document/doc_199/label'\n",
      "X_train size: torch.Size([65, 1, 768])\tY_train size: torch.Size([65])\n",
      "Tensor saved to '../train_document/doc_200/embedding'\n",
      "Tensor saved to '../train_document/doc_200/label'\n",
      "X_train size: torch.Size([74, 1, 768])\tY_train size: torch.Size([74])\n",
      "Tensor saved to '../train_document/doc_201/embedding'\n",
      "Tensor saved to '../train_document/doc_201/label'\n",
      "X_train size: torch.Size([92, 1, 768])\tY_train size: torch.Size([92])\n",
      "Tensor saved to '../train_document/doc_202/embedding'\n",
      "Tensor saved to '../train_document/doc_202/label'\n",
      "X_train size: torch.Size([240, 1, 768])\tY_train size: torch.Size([240])\n",
      "Tensor saved to '../train_document/doc_203/embedding'\n",
      "Tensor saved to '../train_document/doc_203/label'\n",
      "X_train size: torch.Size([102, 1, 768])\tY_train size: torch.Size([102])\n",
      "Tensor saved to '../train_document/doc_204/embedding'\n",
      "Tensor saved to '../train_document/doc_204/label'\n",
      "X_train size: torch.Size([107, 1, 768])\tY_train size: torch.Size([107])\n",
      "Tensor saved to '../train_document/doc_205/embedding'\n",
      "Tensor saved to '../train_document/doc_205/label'\n",
      "X_train size: torch.Size([79, 1, 768])\tY_train size: torch.Size([79])\n",
      "Tensor saved to '../train_document/doc_206/embedding'\n",
      "Tensor saved to '../train_document/doc_206/label'\n",
      "X_train size: torch.Size([168, 1, 768])\tY_train size: torch.Size([168])\n",
      "Tensor saved to '../train_document/doc_207/embedding'\n",
      "Tensor saved to '../train_document/doc_207/label'\n",
      "X_train size: torch.Size([181, 1, 768])\tY_train size: torch.Size([181])\n",
      "Tensor saved to '../train_document/doc_208/embedding'\n",
      "Tensor saved to '../train_document/doc_208/label'\n",
      "X_train size: torch.Size([53, 1, 768])\tY_train size: torch.Size([53])\n",
      "Tensor saved to '../train_document/doc_209/embedding'\n",
      "Tensor saved to '../train_document/doc_209/label'\n",
      "X_train size: torch.Size([248, 1, 768])\tY_train size: torch.Size([248])\n",
      "Tensor saved to '../train_document/doc_210/embedding'\n",
      "Tensor saved to '../train_document/doc_210/label'\n",
      "X_train size: torch.Size([141, 1, 768])\tY_train size: torch.Size([141])\n",
      "Tensor saved to '../train_document/doc_211/embedding'\n",
      "Tensor saved to '../train_document/doc_211/label'\n",
      "X_train size: torch.Size([47, 1, 768])\tY_train size: torch.Size([47])\n",
      "Tensor saved to '../train_document/doc_212/embedding'\n",
      "Tensor saved to '../train_document/doc_212/label'\n",
      "X_train size: torch.Size([81, 1, 768])\tY_train size: torch.Size([81])\n",
      "Tensor saved to '../train_document/doc_213/embedding'\n",
      "Tensor saved to '../train_document/doc_213/label'\n",
      "X_train size: torch.Size([82, 1, 768])\tY_train size: torch.Size([82])\n",
      "Tensor saved to '../train_document/doc_214/embedding'\n",
      "Tensor saved to '../train_document/doc_214/label'\n",
      "X_train size: torch.Size([60, 1, 768])\tY_train size: torch.Size([60])\n",
      "Tensor saved to '../train_document/doc_215/embedding'\n",
      "Tensor saved to '../train_document/doc_215/label'\n",
      "X_train size: torch.Size([179, 1, 768])\tY_train size: torch.Size([179])\n",
      "Tensor saved to '../train_document/doc_216/embedding'\n",
      "Tensor saved to '../train_document/doc_216/label'\n",
      "X_train size: torch.Size([65, 1, 768])\tY_train size: torch.Size([65])\n",
      "Tensor saved to '../train_document/doc_217/embedding'\n",
      "Tensor saved to '../train_document/doc_217/label'\n",
      "X_train size: torch.Size([176, 1, 768])\tY_train size: torch.Size([176])\n",
      "Tensor saved to '../train_document/doc_218/embedding'\n",
      "Tensor saved to '../train_document/doc_218/label'\n",
      "X_train size: torch.Size([283, 1, 768])\tY_train size: torch.Size([283])\n",
      "Tensor saved to '../train_document/doc_219/embedding'\n",
      "Tensor saved to '../train_document/doc_219/label'\n",
      "X_train size: torch.Size([123, 1, 768])\tY_train size: torch.Size([123])\n",
      "Tensor saved to '../train_document/doc_220/embedding'\n",
      "Tensor saved to '../train_document/doc_220/label'\n",
      "X_train size: torch.Size([263, 1, 768])\tY_train size: torch.Size([263])\n",
      "Tensor saved to '../train_document/doc_221/embedding'\n",
      "Tensor saved to '../train_document/doc_221/label'\n",
      "X_train size: torch.Size([58, 1, 768])\tY_train size: torch.Size([58])\n",
      "Tensor saved to '../train_document/doc_222/embedding'\n",
      "Tensor saved to '../train_document/doc_222/label'\n",
      "X_train size: torch.Size([193, 1, 768])\tY_train size: torch.Size([193])\n",
      "Tensor saved to '../train_document/doc_223/embedding'\n",
      "Tensor saved to '../train_document/doc_223/label'\n",
      "X_train size: torch.Size([150, 1, 768])\tY_train size: torch.Size([150])\n",
      "Tensor saved to '../train_document/doc_224/embedding'\n",
      "Tensor saved to '../train_document/doc_224/label'\n",
      "X_train size: torch.Size([0, 1, 768])\tY_train size: torch.Size([0])\n",
      "Tensor saved to '../train_document/doc_225/embedding'\n",
      "Tensor saved to '../train_document/doc_225/label'\n",
      "X_train size: torch.Size([148, 1, 768])\tY_train size: torch.Size([148])\n",
      "Tensor saved to '../train_document/doc_226/embedding'\n",
      "Tensor saved to '../train_document/doc_226/label'\n",
      "X_train size: torch.Size([45, 1, 768])\tY_train size: torch.Size([45])\n",
      "Tensor saved to '../train_document/doc_227/embedding'\n",
      "Tensor saved to '../train_document/doc_227/label'\n",
      "X_train size: torch.Size([255, 1, 768])\tY_train size: torch.Size([255])\n",
      "Tensor saved to '../train_document/doc_228/embedding'\n",
      "Tensor saved to '../train_document/doc_228/label'\n",
      "X_train size: torch.Size([66, 1, 768])\tY_train size: torch.Size([66])\n",
      "Tensor saved to '../train_document/doc_229/embedding'\n",
      "Tensor saved to '../train_document/doc_229/label'\n",
      "X_train size: torch.Size([62, 1, 768])\tY_train size: torch.Size([62])\n",
      "Tensor saved to '../train_document/doc_230/embedding'\n",
      "Tensor saved to '../train_document/doc_230/label'\n",
      "X_train size: torch.Size([214, 1, 768])\tY_train size: torch.Size([214])\n",
      "Tensor saved to '../train_document/doc_231/embedding'\n",
      "Tensor saved to '../train_document/doc_231/label'\n",
      "X_train size: torch.Size([246, 1, 768])\tY_train size: torch.Size([246])\n",
      "Tensor saved to '../train_document/doc_232/embedding'\n",
      "Tensor saved to '../train_document/doc_232/label'\n",
      "X_train size: torch.Size([110, 1, 768])\tY_train size: torch.Size([110])\n",
      "Tensor saved to '../train_document/doc_233/embedding'\n",
      "Tensor saved to '../train_document/doc_233/label'\n",
      "X_train size: torch.Size([110, 1, 768])\tY_train size: torch.Size([110])\n",
      "Tensor saved to '../train_document/doc_234/embedding'\n",
      "Tensor saved to '../train_document/doc_234/label'\n",
      "X_train size: torch.Size([67, 1, 768])\tY_train size: torch.Size([67])\n",
      "Tensor saved to '../train_document/doc_235/embedding'\n",
      "Tensor saved to '../train_document/doc_235/label'\n",
      "X_train size: torch.Size([73, 1, 768])\tY_train size: torch.Size([73])\n",
      "Tensor saved to '../train_document/doc_236/embedding'\n",
      "Tensor saved to '../train_document/doc_236/label'\n",
      "X_train size: torch.Size([56, 1, 768])\tY_train size: torch.Size([56])\n",
      "Tensor saved to '../train_document/doc_237/embedding'\n",
      "Tensor saved to '../train_document/doc_237/label'\n",
      "X_train size: torch.Size([212, 1, 768])\tY_train size: torch.Size([212])\n",
      "Tensor saved to '../train_document/doc_238/embedding'\n",
      "Tensor saved to '../train_document/doc_238/label'\n",
      "X_train size: torch.Size([215, 1, 768])\tY_train size: torch.Size([215])\n",
      "Tensor saved to '../train_document/doc_239/embedding'\n",
      "Tensor saved to '../train_document/doc_239/label'\n",
      "X_train size: torch.Size([103, 1, 768])\tY_train size: torch.Size([103])\n",
      "Tensor saved to '../train_document/doc_240/embedding'\n",
      "Tensor saved to '../train_document/doc_240/label'\n",
      "X_train size: torch.Size([45, 1, 768])\tY_train size: torch.Size([45])\n",
      "Tensor saved to '../train_document/doc_241/embedding'\n",
      "Tensor saved to '../train_document/doc_241/label'\n",
      "X_train size: torch.Size([112, 1, 768])\tY_train size: torch.Size([112])\n",
      "Tensor saved to '../train_document/doc_242/embedding'\n",
      "Tensor saved to '../train_document/doc_242/label'\n",
      "X_train size: torch.Size([77, 1, 768])\tY_train size: torch.Size([77])\n",
      "Tensor saved to '../train_document/doc_243/embedding'\n",
      "Tensor saved to '../train_document/doc_243/label'\n",
      "X_train size: torch.Size([90, 1, 768])\tY_train size: torch.Size([90])\n",
      "Tensor saved to '../train_document/doc_244/embedding'\n",
      "Tensor saved to '../train_document/doc_244/label'\n",
      "X_train size: torch.Size([122, 1, 768])\tY_train size: torch.Size([122])\n",
      "Tensor saved to '../train_document/doc_245/embedding'\n",
      "Tensor saved to '../train_document/doc_245/label'\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(doc_idxs)):\n",
    "    TRAIN_emb, TRAIN_labels = get_model_data_batched(doc_idxs[idx], batched_texts[idx], batched_labels[idx],label_encoder,max_lens_train)\n",
    "    save_tensor(TRAIN_emb, '../train_document/doc_'+str(idx),\"embedding\")\n",
    "    save_tensor(TRAIN_labels, '../train_document/doc_'+str(idx),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idxs, batched_texts, batched_labels = get_batched_data(TEST_data, batch_size= 1)\n",
    "max_lens_test = max_length(TEST_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: torch.Size([96, 1, 768])\tY_train size: torch.Size([96])\n",
      "Tensor saved to '../test_document/doc_0/embedding'\n",
      "Tensor saved to '../test_document/doc_0/label'\n",
      "X_train size: torch.Size([139, 1, 768])\tY_train size: torch.Size([139])\n",
      "Tensor saved to '../test_document/doc_1/embedding'\n",
      "Tensor saved to '../test_document/doc_1/label'\n",
      "X_train size: torch.Size([150, 1, 768])\tY_train size: torch.Size([150])\n",
      "Tensor saved to '../test_document/doc_2/embedding'\n",
      "Tensor saved to '../test_document/doc_2/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../test_document/doc_3/embedding'\n",
      "Tensor saved to '../test_document/doc_3/label'\n",
      "X_train size: torch.Size([97, 1, 768])\tY_train size: torch.Size([97])\n",
      "Tensor saved to '../test_document/doc_4/embedding'\n",
      "Tensor saved to '../test_document/doc_4/label'\n",
      "X_train size: torch.Size([57, 1, 768])\tY_train size: torch.Size([57])\n",
      "Tensor saved to '../test_document/doc_5/embedding'\n",
      "Tensor saved to '../test_document/doc_5/label'\n",
      "X_train size: torch.Size([68, 1, 768])\tY_train size: torch.Size([68])\n",
      "Tensor saved to '../test_document/doc_6/embedding'\n",
      "Tensor saved to '../test_document/doc_6/label'\n",
      "X_train size: torch.Size([113, 1, 768])\tY_train size: torch.Size([113])\n",
      "Tensor saved to '../test_document/doc_7/embedding'\n",
      "Tensor saved to '../test_document/doc_7/label'\n",
      "X_train size: torch.Size([199, 1, 768])\tY_train size: torch.Size([199])\n",
      "Tensor saved to '../test_document/doc_8/embedding'\n",
      "Tensor saved to '../test_document/doc_8/label'\n",
      "X_train size: torch.Size([139, 1, 768])\tY_train size: torch.Size([139])\n",
      "Tensor saved to '../test_document/doc_9/embedding'\n",
      "Tensor saved to '../test_document/doc_9/label'\n",
      "X_train size: torch.Size([76, 1, 768])\tY_train size: torch.Size([76])\n",
      "Tensor saved to '../test_document/doc_10/embedding'\n",
      "Tensor saved to '../test_document/doc_10/label'\n",
      "X_train size: torch.Size([104, 1, 768])\tY_train size: torch.Size([104])\n",
      "Tensor saved to '../test_document/doc_11/embedding'\n",
      "Tensor saved to '../test_document/doc_11/label'\n",
      "X_train size: torch.Size([209, 1, 768])\tY_train size: torch.Size([209])\n",
      "Tensor saved to '../test_document/doc_12/embedding'\n",
      "Tensor saved to '../test_document/doc_12/label'\n",
      "X_train size: torch.Size([135, 1, 768])\tY_train size: torch.Size([135])\n",
      "Tensor saved to '../test_document/doc_13/embedding'\n",
      "Tensor saved to '../test_document/doc_13/label'\n",
      "X_train size: torch.Size([64, 1, 768])\tY_train size: torch.Size([64])\n",
      "Tensor saved to '../test_document/doc_14/embedding'\n",
      "Tensor saved to '../test_document/doc_14/label'\n",
      "X_train size: torch.Size([62, 1, 768])\tY_train size: torch.Size([62])\n",
      "Tensor saved to '../test_document/doc_15/embedding'\n",
      "Tensor saved to '../test_document/doc_15/label'\n",
      "X_train size: torch.Size([98, 1, 768])\tY_train size: torch.Size([98])\n",
      "Tensor saved to '../test_document/doc_16/embedding'\n",
      "Tensor saved to '../test_document/doc_16/label'\n",
      "X_train size: torch.Size([111, 1, 768])\tY_train size: torch.Size([111])\n",
      "Tensor saved to '../test_document/doc_17/embedding'\n",
      "Tensor saved to '../test_document/doc_17/label'\n",
      "X_train size: torch.Size([62, 1, 768])\tY_train size: torch.Size([62])\n",
      "Tensor saved to '../test_document/doc_18/embedding'\n",
      "Tensor saved to '../test_document/doc_18/label'\n",
      "X_train size: torch.Size([130, 1, 768])\tY_train size: torch.Size([130])\n",
      "Tensor saved to '../test_document/doc_19/embedding'\n",
      "Tensor saved to '../test_document/doc_19/label'\n",
      "X_train size: torch.Size([46, 1, 768])\tY_train size: torch.Size([46])\n",
      "Tensor saved to '../test_document/doc_20/embedding'\n",
      "Tensor saved to '../test_document/doc_20/label'\n",
      "X_train size: torch.Size([66, 1, 768])\tY_train size: torch.Size([66])\n",
      "Tensor saved to '../test_document/doc_21/embedding'\n",
      "Tensor saved to '../test_document/doc_21/label'\n",
      "X_train size: torch.Size([77, 1, 768])\tY_train size: torch.Size([77])\n",
      "Tensor saved to '../test_document/doc_22/embedding'\n",
      "Tensor saved to '../test_document/doc_22/label'\n",
      "X_train size: torch.Size([53, 1, 768])\tY_train size: torch.Size([53])\n",
      "Tensor saved to '../test_document/doc_23/embedding'\n",
      "Tensor saved to '../test_document/doc_23/label'\n",
      "X_train size: torch.Size([112, 1, 768])\tY_train size: torch.Size([112])\n",
      "Tensor saved to '../test_document/doc_24/embedding'\n",
      "Tensor saved to '../test_document/doc_24/label'\n",
      "X_train size: torch.Size([186, 1, 768])\tY_train size: torch.Size([186])\n",
      "Tensor saved to '../test_document/doc_25/embedding'\n",
      "Tensor saved to '../test_document/doc_25/label'\n",
      "X_train size: torch.Size([54, 1, 768])\tY_train size: torch.Size([54])\n",
      "Tensor saved to '../test_document/doc_26/embedding'\n",
      "Tensor saved to '../test_document/doc_26/label'\n",
      "X_train size: torch.Size([43, 1, 768])\tY_train size: torch.Size([43])\n",
      "Tensor saved to '../test_document/doc_27/embedding'\n",
      "Tensor saved to '../test_document/doc_27/label'\n",
      "X_train size: torch.Size([59, 1, 768])\tY_train size: torch.Size([59])\n",
      "Tensor saved to '../test_document/doc_28/embedding'\n",
      "Tensor saved to '../test_document/doc_28/label'\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(doc_idxs)):\n",
    "    TEST_emb, TEST_labels = get_model_data_batched(doc_idxs[idx], batched_texts[idx], batched_labels[idx],label_encoder,max_lens_test)\n",
    "    save_tensor(TEST_emb, '../test_document/doc_'+str(idx),\"embedding\")\n",
    "    save_tensor(TEST_labels, '../test_document/doc_'+str(idx),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 1, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_tensor(f\"../train_document/doc_{69}/embedding\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
